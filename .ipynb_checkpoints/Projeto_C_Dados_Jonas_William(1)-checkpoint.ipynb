{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nome**: Jonas da Silva Lopes\n",
    "\n",
    "**Nome**: William Silva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Classificador autom√°tico de sentimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install tweepy\n",
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import emoji\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "import re \n",
    "import functools\n",
    "import operator\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***@William48253649***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Identificador da conta no twitter: @William48253649\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido\n",
    "produto = 'Nubank'\n",
    "\n",
    "#Quantidade m√≠nima de mensagens capturadas\n",
    "n = 500\n",
    "#Quantidade m√≠nima de mensagens para a base de treinamento\n",
    "t = 300\n",
    "\n",
    "#Filtro de l√≠ngua\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "    msgs.append(msg.full_text.lower()) #Lower para deixar tudo min√∫sculo e facilitar a compara√ß√£o\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um poss√≠vel vi√©s\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo n√£o existe para n√£o substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])}).set()\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])}).set()\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Ap√≥s realizar a classifica√ß√£o manual das mensagens, como irrelevante (0) ou relevante (1), partimos para  a mudan√ßa desses valores para algo mais palp√°vel para a an√°lise. Com isso, fazemos a altera√ß√£o que pode ser vista abaixo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas, para realizar isso, primeiro foi necess√°rio determinar crit√©rios para a classifica√ß√£o:\n",
    "\n",
    "- Mencionar o produto;\n",
    "- A men√ß√£o ao produto deve ser acompanhada de uma opini√£o;\n",
    "- A opini√£o pode ser demonstrada na forma de indaga√ß√µes, reclama√ß√µes, pode envolver sarcasmo, elogios e sugest√µes sobre servi√ßos;\n",
    "- A opini√£o afirmada deve ser clara;\n",
    "- Emoctions tamb√©m representam opini√µes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A quantidade de cada cada um √©: \n",
      "\n",
      " Irrelevante    184\n",
      "Relevante      116\n",
      "Name: Relev√¢ncia, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "mensagens = pd.read_excel(\"Nubank.xlsx\")\n",
    "mensagens.Relev√¢ncia = mensagens.Relev√¢ncia.astype('category')\n",
    "mensagens.Relev√¢ncia.cat.categories = ('Irrelevante', 'Relevante')\n",
    "\n",
    "print(\"A quantidade de cada cada um √©: \\n\\n\", mensagens.Relev√¢ncia.value_counts())\n",
    "\n",
    "relevante = mensagens[mensagens.Relev√¢ncia==\"Relevante\"]\n",
    "irrelevante = mensagens[mensagens.Relev√¢ncia==\"Irrelevante\"]\n",
    "\n",
    "total = len(relevante) + len(irrelevante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A probabilidade de ser relevante √© 38.666666666666664 %\n",
      "A probabilidade de ser irrelevante √© 61.33333333333333 %\n"
     ]
    }
   ],
   "source": [
    "'''A Partir dos dados obtidos, nota-se que:\n",
    "        p(relevante) = 116/300\n",
    "        p(irrelevante) = 184/300\n",
    "'''\n",
    "p_relev = 116/300*100\n",
    "print(\"A probabilidade de ser relevante √©\", p_relev, \"%\")\n",
    "\n",
    "p_irrelev = 184/300*100\n",
    "print(\"A probabilidade de ser irrelevante √©\", p_irrelev, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      rindo mas preocupada pois cada dia parece que ...\n",
       "6          eu amo o nubank mesmo https://t.co/rrpb89yes9\n",
       "7      meu pai pediu um cart√£o novo pra mim pra pegar...\n",
       "8          quem inventou o nubank nem √© gente, √© um anjo\n",
       "11     @castrocastrado @nubank se quiser eu te indico...\n",
       "12     @1masterball @haunted_electra me assusta muito...\n",
       "13     preju√≠zo nubank: banco tem 12 milh√µes de clien...\n",
       "15     @marialmeida93 @thaioliv_ @nubank menina que t...\n",
       "19     @nubank @itoncrf_ e assim mesmo n me aprovaram...\n",
       "21          depois de anos tentando,fui aceita no nubank\n",
       "22     rt @afropreticinha: aff coma assim o cart√£o da...\n",
       "25     fiquei assustada quando vi que minha fatura do...\n",
       "26     nubank nunca me liberou cr√©dito, agr q libera....\n",
       "27               meu nubank chegouüòç vos declaro fal√™ncia\n",
       "28     @lucasafoliveira @nubank ele trava assim e n√£o...\n",
       "31     s√©rio, se eu perder minha bolsa por conta do n...\n",
       "32        eu toda com meu nubank https://t.co/4av08gusbn\n",
       "33     querido @nubank, a gente queria tanto testar e...\n",
       "34     eu amo o @nubank de verdade, de cora√ß√£o, mas n...\n",
       "36     esperando o @nubank lan√ßar seu plano de previd...\n",
       "42     felizmente a nubank me aceitou esse momento √© ...\n",
       "44                         feliz q a nubank me aceitouuu\n",
       "45     maior defeito da nubank √© a facilidade p clona...\n",
       "46     eu n√£o tenho cart√£o nubank, mas eu amo essa ca...\n",
       "48     o @nubank n√£o libera a op√ß√£o de credito pro me...\n",
       "56     @robzgf quer mimo maior que um cart√£o livre de...\n",
       "57     @nubank @awarenesswoman @mabzinhaa a√≠ nubankin...\n",
       "59     eu: nossa vou ser mais reservada sabe n vou fa...\n",
       "60     estou muito orgulhoso da equipe de vendas. mes...\n",
       "63     eu ia ficar um nojo se o nubank autorizasse pa...\n",
       "                             ...                        \n",
       "231      @maluulana @nubank e eu ainda na eterna espera.\n",
       "233    pq q eu fui a √∫nica pessoa do mundo q n√£o ganh...\n",
       "234    @pianoetlux bah nem, nubank me odeia, eles me ...\n",
       "236    a central de atendimento da nubank √© me trata ...\n",
       "239    eu t√¥ assi\\npena que j√° vai tudo s√≥ hoje \\nnub...\n",
       "241    @1masterball eu tinha medo de fazer um nubank,...\n",
       "244    nubank ta cheio desses problema ai, tenho √© me...\n",
       "247    @valeriaales @nandoida @helogb__ @nubank @nuba...\n",
       "248    gente, j√° imaginou q louco se d√° um problema c...\n",
       "250                  estou ansiosa pro meu nubank chegar\n",
       "252    seria tao lindo se a @nubank deixasse eu fazer...\n",
       "254                           meu cart√£o nubank chegou ü§ó\n",
       "255    @dgianygarcia deus que me livre, esse nubank q...\n",
       "259    @nubank ai voc√™s s√£o queridos demais ‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è ob...\n",
       "260    isso tem acontecido demais com o nubank, pelo ...\n",
       "261                           @nubank conte cmg pra tudo\n",
       "264    euzinha. inclusive, @nubank aumenta meu limite...\n",
       "265    bixo o atendimento do @nubank √© sensacional, c...\n",
       "268                         nubank √© o melhor banco, pqp\n",
       "274    next e nubank duas bombas, essas porras n√£o li...\n",
       "279    @lanaalmeidaofc @nubank nunca decepciona, o me...\n",
       "280    @__chicao__ @nubank o meu a \"sorte\" √© que foi ...\n",
       "283    eu perguntei de um amigo se ele queria que eu ...\n",
       "287    n√£o aguento mais o @nubank  me lembrando de pa...\n",
       "289    aconteceu o mesmo comigo, compraram enxoval de...\n",
       "290    @nubank corre aqui por favor, to perdida. o ch...\n",
       "292    @__chicao__ @gtcarvalh0 @nubank passei por iss...\n",
       "296    to desde o dia 1¬∫ tentando pagar a porra da mi...\n",
       "298    @nubank @yasuqh kakakakakakkak pqp eu quero se...\n",
       "299    @1masterball @renatojg nossa! clonaram um nuba...\n",
       "Name: Treinamento, Length: 116, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Fun√ß√£o que troca pontua√ß√£o por espa√ßo '''\n",
    "def cleanup(text):\n",
    "    punctuation = '[!\\-.:?;/,|@\"\\'()]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    # Abaixo, determina que se troca por espa√ßo\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    \n",
    "    emoji_dividir = emoji.get_emoji_regexp().split(text_subbed)\n",
    "    espaco_dividir = [substr.split() for substr in emoji_dividir]\n",
    "    split = functools.reduce(operator.concat, espaco_dividir)\n",
    "    \n",
    "    return split\n",
    "\n",
    "# Usando a fun√ß√£o apply para fazer a limpeza nas mensagens\n",
    "nubank_relev = relevante.Treinamento.apply(cleanup)\n",
    "nubank_irrelev = irrelevante.Treinamento.apply(cleanup)\n",
    "\n",
    "# Pegando as palavras da lista de Relevantes para contar\n",
    "def pega_text(texto):\n",
    "    # Pega as palavras para colocar numa lista\n",
    "    lista = []\n",
    "    i = 0\n",
    "    for linha in texto:\n",
    "        if len(linha) > 1:\n",
    "            while i < len(linha):\n",
    "                lista.append(linha[i])\n",
    "                i += 1  \n",
    "            i = 0\n",
    "        elif len(linha) != 1 and (len(linha)-1) != 1:\n",
    "            a = texto\n",
    "            return a \n",
    "    return lista\n",
    "\n",
    "relevante.Treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequ√™ncia Absoluta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nubank               122\n",
       "o                     58\n",
       "de                    54\n",
       "e                     52\n",
       "eu                    47\n",
       "que                   45\n",
       "a                     35\n",
       "meu                   34\n",
       "me                    29\n",
       "t                     28\n",
       "https                 28\n",
       "co                    28\n",
       "um                    27\n",
       "n√£o                   26\n",
       "√©                     25\n",
       "cart√£o                23\n",
       "do                    23\n",
       "no                    20\n",
       "uma                   16\n",
       "q                     15\n",
       "pra                   15\n",
       "na                    15\n",
       "com                   14\n",
       "to                    14\n",
       "s√≥                    13\n",
       "limite                12\n",
       "mais                  12\n",
       "nunca                 11\n",
       "tem                   11\n",
       "da                    11\n",
       "                    ... \n",
       "falar                  1\n",
       "silva                  1\n",
       "cu                     1\n",
       "final                  1\n",
       "r$                     1\n",
       "percebo                1\n",
       "objetivo               1\n",
       "bb                     1\n",
       "pega                   1\n",
       "bombas                 1\n",
       "pud√©ssemos             1\n",
       "demoraram              1\n",
       "nenhuma                1\n",
       "buscar                 1\n",
       "resposta               1\n",
       "in√≠cio                 1\n",
       "ela                    1\n",
       "pais                   1\n",
       "to6j46gsrr             1\n",
       "agressiva              1\n",
       "almeida                1\n",
       "clonagem               1\n",
       "declaro                1\n",
       "0b3igvmynt             1\n",
       "rappibrasil            1\n",
       "precisei               1\n",
       "nessa                  1\n",
       "negocinho=3+horas      1\n",
       "ita√∫                   1\n",
       "blindadah              1\n",
       "Name: 0, Length: 833, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Frequ√™ncia dos Relevantes\n",
    "lista_nubank_relev = pd.DataFrame(pega_text(nubank_relev))\n",
    "lista_nubank_relev[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Irrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nubank          154\n",
       "o                71\n",
       "de               67\n",
       "e                62\n",
       "que              60\n",
       "t                58\n",
       "https            58\n",
       "co               58\n",
       "a                57\n",
       "n√£o              52\n",
       "√©                38\n",
       "um               36\n",
       "eu               34\n",
       "da               33\n",
       "com              33\n",
       "do               31\n",
       "se               30\n",
       "gente            29\n",
       "rt               28\n",
       "tem              28\n",
       "meu              26\n",
       "pra              26\n",
       "em               25\n",
       "no               25\n",
       "cart√£o           24\n",
       "na               24\n",
       "voc√™             24\n",
       "uma              22\n",
       "conta            22\n",
       "s√≥               22\n",
       "               ... \n",
       "tantas            1\n",
       "amores            1\n",
       "aplicado          1\n",
       "pagou             1\n",
       "modelos           1\n",
       "sp                1\n",
       "tiamu             1\n",
       "conseguindo       1\n",
       "vazou             1\n",
       "helogb__          1\n",
       "correios          1\n",
       "douglas           1\n",
       "negativo          1\n",
       "conseguir         1\n",
       "trancado          1\n",
       "pqp               1\n",
       "desbloquea‚Ä¶       1\n",
       "grandes           1\n",
       "preciso           1\n",
       "luizaamorim_      1\n",
       "seventeen         1\n",
       "transporte        1\n",
       "d√©bito            1\n",
       "helton            1\n",
       "tinham            1\n",
       "_owrosa           1\n",
       "tom               1\n",
       "acabar            1\n",
       "solicitar         1\n",
       "pelos             1\n",
       "Name: 0, Length: 1114, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Frequ√™ncia dos Irrelevantes\n",
    "lista_nubank_irrelev = pd.DataFrame(pega_text(nubank_irrelev))\n",
    "lista_nubank_irrelev[0].value_counts()\n",
    "lista_nubank_irrelev[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequ√™ncia Relativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nubank               0.056092\n",
       "o                    0.026667\n",
       "de                   0.024828\n",
       "e                    0.023908\n",
       "eu                   0.021609\n",
       "que                  0.020690\n",
       "a                    0.016092\n",
       "meu                  0.015632\n",
       "me                   0.013333\n",
       "t                    0.012874\n",
       "https                0.012874\n",
       "co                   0.012874\n",
       "um                   0.012414\n",
       "n√£o                  0.011954\n",
       "√©                    0.011494\n",
       "cart√£o               0.010575\n",
       "do                   0.010575\n",
       "no                   0.009195\n",
       "uma                  0.007356\n",
       "q                    0.006897\n",
       "pra                  0.006897\n",
       "na                   0.006897\n",
       "com                  0.006437\n",
       "to                   0.006437\n",
       "s√≥                   0.005977\n",
       "limite               0.005517\n",
       "mais                 0.005517\n",
       "nunca                0.005057\n",
       "tem                  0.005057\n",
       "da                   0.005057\n",
       "                       ...   \n",
       "falar                0.000460\n",
       "silva                0.000460\n",
       "cu                   0.000460\n",
       "final                0.000460\n",
       "r$                   0.000460\n",
       "percebo              0.000460\n",
       "objetivo             0.000460\n",
       "bb                   0.000460\n",
       "pega                 0.000460\n",
       "bombas               0.000460\n",
       "pud√©ssemos           0.000460\n",
       "demoraram            0.000460\n",
       "nenhuma              0.000460\n",
       "buscar               0.000460\n",
       "resposta             0.000460\n",
       "in√≠cio               0.000460\n",
       "ela                  0.000460\n",
       "pais                 0.000460\n",
       "to6j46gsrr           0.000460\n",
       "agressiva            0.000460\n",
       "almeida              0.000460\n",
       "clonagem             0.000460\n",
       "declaro              0.000460\n",
       "0b3igvmynt           0.000460\n",
       "rappibrasil          0.000460\n",
       "precisei             0.000460\n",
       "nessa                0.000460\n",
       "negocinho=3+horas    0.000460\n",
       "ita√∫                 0.000460\n",
       "blindadah            0.000460\n",
       "Name: 0, Length: 833, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_nubank_relev[0].value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Irrelevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nubank          0.045441\n",
       "o               0.020950\n",
       "de              0.019770\n",
       "e               0.018294\n",
       "que             0.017704\n",
       "t               0.017114\n",
       "https           0.017114\n",
       "co              0.017114\n",
       "a               0.016819\n",
       "n√£o             0.015344\n",
       "√©               0.011213\n",
       "um              0.010623\n",
       "eu              0.010032\n",
       "da              0.009737\n",
       "com             0.009737\n",
       "do              0.009147\n",
       "se              0.008852\n",
       "gente           0.008557\n",
       "rt              0.008262\n",
       "tem             0.008262\n",
       "meu             0.007672\n",
       "pra             0.007672\n",
       "em              0.007377\n",
       "no              0.007377\n",
       "cart√£o          0.007082\n",
       "na              0.007082\n",
       "voc√™            0.007082\n",
       "uma             0.006492\n",
       "conta           0.006492\n",
       "s√≥              0.006492\n",
       "                  ...   \n",
       "tantas          0.000295\n",
       "amores          0.000295\n",
       "aplicado        0.000295\n",
       "pagou           0.000295\n",
       "modelos         0.000295\n",
       "sp              0.000295\n",
       "tiamu           0.000295\n",
       "conseguindo     0.000295\n",
       "vazou           0.000295\n",
       "helogb__        0.000295\n",
       "correios        0.000295\n",
       "douglas         0.000295\n",
       "negativo        0.000295\n",
       "conseguir       0.000295\n",
       "trancado        0.000295\n",
       "pqp             0.000295\n",
       "desbloquea‚Ä¶     0.000295\n",
       "grandes         0.000295\n",
       "preciso         0.000295\n",
       "luizaamorim_    0.000295\n",
       "seventeen       0.000295\n",
       "transporte      0.000295\n",
       "d√©bito          0.000295\n",
       "helton          0.000295\n",
       "tinham          0.000295\n",
       "_owrosa         0.000295\n",
       "tom             0.000295\n",
       "acabar          0.000295\n",
       "solicitar       0.000295\n",
       "pelos           0.000295\n",
       "Name: 0, Length: 1114, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_nubank_irrelev[0].value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_counts_relevante=(lista_nubank_relev[0].value_counts()).to_dict()\n",
    "dicionario_counts_relevancia = (mensagens.Relev√¢ncia.value_counts()).to_dict()\n",
    "\n",
    "i = 11\n",
    "linhas_mens = mensagens.Treinamento.apply(cleanup)[i]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.45026357029665e-24\n"
     ]
    }
   ],
   "source": [
    "def probabilidade_do_naive(mensagens, lista_counts_relevante, dicionario_counts_relevancia, total, linhas_mens):\n",
    "    verossimilhan√ßa =1\n",
    "    for word in linhas_mens:\n",
    "        for key,values in lista_counts_relevante.items():\n",
    "            if key == word:\n",
    "                verossimilhan√ßa *= (values+1)/len(lista_nubank_relev)\n",
    "    \n",
    "    for rel, v in dicionario_counts_relevancia.items():\n",
    "        if rel == \"Relevante\":\n",
    "            total_rel = v\n",
    "    priori = total_rel/total\n",
    "    \n",
    "    \n",
    "    return verossimilhan√ßa*priori\n",
    "print(probabilidade_do_naive(mensagens, lista_counts_relevante, dicionario_counts_relevancia, total, linhas_mens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nlinhas_mens = mensagens.Treinamento.apply(cleanup)[i]\\nprobs[i] = probabilidade_do_naive(mensagens, lista_counts_relevante, dicionario_counts_relevancia, total, linhas_mens)\\nprobs\\n'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = [0]*300\n",
    "\n",
    "i = 0\n",
    "for h in probs:\n",
    "    linhas_mens = mensagens.Treinamento.apply(cleanup)[i]\n",
    "    probs[i] = probabilidade_do_naive(mensagens, lista_counts_relevante, dicionario_counts_relevancia, total, linhas_mens)\n",
    "    i +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza an√°lise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
