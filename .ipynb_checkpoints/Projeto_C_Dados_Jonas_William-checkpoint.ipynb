{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nome**: Jonas da Silva Lopes\n",
    "\n",
    "**Nome**: William Silva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Classificador autom√°tico de sentimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "import re \n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***@William48253649***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Identificador da conta no twitter: @William48253649\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido\n",
    "produto = 'Nubank'\n",
    "\n",
    "#Quantidade m√≠nima de mensagens capturadas\n",
    "n = 500\n",
    "#Quantidade m√≠nima de mensagens para a base de treinamento\n",
    "t = 300\n",
    "\n",
    "#Filtro de l√≠ngua\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "    msgs.append(msg.full_text.lower()) #Lower para deixar tudo min√∫sculo e facilitar a compara√ß√£o\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um poss√≠vel vi√©s\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo n√£o existe para n√£o substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])})\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])})\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Ap√≥s realizar a classifica√ß√£o manual das mensagens, como irrelevante (0) ou relevante (1), partimos para  a mudan√ßa desses valores para algo mais palp√°vel para a an√°lise. Com isso, fazemos a altera√ß√£o que pode ser vista abaixo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas, para realizar isso, primeiro foi necess√°rio determinar crit√©rios para a classifica√ß√£o:\n",
    "\n",
    "- Mencionar o produto;\n",
    "- A men√ß√£o ao produto deve ser acompanhada de uma opini√£o;\n",
    "- A opini√£o pode ser demonstrada na forma de indaga√ß√µes, reclama√ß√µes, pode envolver sarcasmo, elogios e sugest√µes sobre servi√ßos;\n",
    "- A opini√£o afirmada deve ser clara;\n",
    "- Emoctions tamb√©m representam opini√µes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A quantidade de cada cada um √©: \n",
      "\n",
      " Irrelevante    184\n",
      "Relevante      116\n",
      "Name: Relev√¢ncia, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "mensagens = pd.read_excel(\"Nubank.xlsx\")\n",
    "mensagens.Relev√¢ncia = mensagens.Relev√¢ncia.astype('category')\n",
    "mensagens.Relev√¢ncia.cat.categories = ('Irrelevante', 'Relevante')\n",
    "\n",
    "print(\"A quantidade de cada cada um √©: \\n\\n\", mensagens.Relev√¢ncia.value_counts())\n",
    "\n",
    "relevante = mensagens[mensagens.Relev√¢ncia==\"Relevante\"]\n",
    "irrelevante = mensagens[mensagens.Relev√¢ncia==\"Irrelevante\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Fun√ß√£o que troca pontua√ß√£o por espa√ßo '''\n",
    "def cleanup(text):\n",
    "    punctuation = '[!\\-.:?;/,|@]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    # Abaixo, determina que se troca por espa√ßo\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed\n",
    "\n",
    "# Usando a fun√ß√£o apply para fazer a limpeza nas mensagens\n",
    "nubank_relev = relevante.Treinamento.apply(cleanup)\n",
    "nubank_irrelev = irrelevante.Treinamento.apply(cleanup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pegando as palavras em cada t√≥pico: Relevante e Irrelevante\n",
    "\n",
    "words_relev = pd.DataFrame(\"\".join(nubank_relev).split())\n",
    "#words_relev[0].value_counts()\n",
    "\n",
    "words_irrelev = pd.DataFrame(\"\".join(nubank_irrelev).split())\n",
    "#words_irrelev[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Frequ√™ncia Absoluta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nubank             113\n",
       "o                   57\n",
       "de                  54\n",
       "e                   52\n",
       "que                 45\n",
       "eu                  38\n",
       "a                   34\n",
       "me                  29\n",
       "t                   28\n",
       "https               28\n",
       "meu                 28\n",
       "co                  28\n",
       "um                  27\n",
       "n√£o                 26\n",
       "√©                   25\n",
       "cart√£o              23\n",
       "do                  23\n",
       "no                  20\n",
       "uma                 16\n",
       "q                   15\n",
       "pra                 15\n",
       "na                  15\n",
       "com                 14\n",
       "s√≥                  13\n",
       "limite              12\n",
       "to                  12\n",
       "mais                12\n",
       "da                  11\n",
       "nunca               11\n",
       "tem                 11\n",
       "                  ... \n",
       "brasil               1\n",
       "pagar√°               1\n",
       "eternidade           1\n",
       "yasuqh               1\n",
       "casos                1\n",
       "digitais             1\n",
       "lucasafoliveira      1\n",
       "resolve              1\n",
       "gastei               1\n",
       "almeida              1\n",
       "diante               1\n",
       "dgianygarcia         1\n",
       "12                   1\n",
       "tal                  1\n",
       "lan√ßar               1\n",
       "nao                  1\n",
       "pianoetlux           1\n",
       "fechamento           1\n",
       "gabriel              1\n",
       "ningu√©m              1\n",
       "ruim                 1\n",
       "üòî                    1\n",
       "olhando              1\n",
       "rrpb89yes9meu        1\n",
       "ifovvyngg9           1\n",
       "motivo               1\n",
       "neeeee               1\n",
       "nubankto             1\n",
       "bom                  1\n",
       "absolutamente        1\n",
       "Name: 0, Length: 850, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_relev[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Frequ√™ncia relativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nubank             0.053656\n",
       "o                  0.027066\n",
       "de                 0.025641\n",
       "e                  0.024691\n",
       "que                0.021368\n",
       "eu                 0.018044\n",
       "a                  0.016144\n",
       "me                 0.013770\n",
       "t                  0.013295\n",
       "https              0.013295\n",
       "meu                0.013295\n",
       "co                 0.013295\n",
       "um                 0.012821\n",
       "n√£o                0.012346\n",
       "√©                  0.011871\n",
       "cart√£o             0.010921\n",
       "do                 0.010921\n",
       "no                 0.009497\n",
       "uma                0.007597\n",
       "q                  0.007123\n",
       "pra                0.007123\n",
       "na                 0.007123\n",
       "com                0.006648\n",
       "s√≥                 0.006173\n",
       "limite             0.005698\n",
       "to                 0.005698\n",
       "mais               0.005698\n",
       "da                 0.005223\n",
       "nunca              0.005223\n",
       "tem                0.005223\n",
       "                     ...   \n",
       "brasil             0.000475\n",
       "pagar√°             0.000475\n",
       "eternidade         0.000475\n",
       "yasuqh             0.000475\n",
       "casos              0.000475\n",
       "digitais           0.000475\n",
       "lucasafoliveira    0.000475\n",
       "resolve            0.000475\n",
       "gastei             0.000475\n",
       "almeida            0.000475\n",
       "diante             0.000475\n",
       "dgianygarcia       0.000475\n",
       "12                 0.000475\n",
       "tal                0.000475\n",
       "lan√ßar             0.000475\n",
       "nao                0.000475\n",
       "pianoetlux         0.000475\n",
       "fechamento         0.000475\n",
       "gabriel            0.000475\n",
       "ningu√©m            0.000475\n",
       "ruim               0.000475\n",
       "üòî                  0.000475\n",
       "olhando            0.000475\n",
       "rrpb89yes9meu      0.000475\n",
       "ifovvyngg9         0.000475\n",
       "motivo             0.000475\n",
       "neeeee             0.000475\n",
       "nubankto           0.000475\n",
       "bom                0.000475\n",
       "absolutamente      0.000475\n",
       "Name: 0, Length: 850, dtype: float64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_relev[0].value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza an√°lise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
