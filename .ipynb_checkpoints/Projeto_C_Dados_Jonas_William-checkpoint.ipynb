{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nome**: Jonas da Silva Lopes\n",
    "\n",
    "**Nome**: William Silva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Classificador automático de sentimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "import re \n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***@William48253649***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Identificador da conta no twitter: @William48253649\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido\n",
    "produto = 'Nubank'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas\n",
    "n = 500\n",
    "#Quantidade mínima de mensagens para a base de treinamento\n",
    "t = 300\n",
    "\n",
    "#Filtro de língua\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "    msgs.append(msg.full_text.lower()) #Lower para deixar tudo minúsculo e facilitar a comparação\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possível viés\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])}).set()\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])}).set()\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Após realizar a classificação manual das mensagens, como irrelevante (0) ou relevante (1), partimos para  a mudança desses valores para algo mais palpável para a análise. Com isso, fazemos a alteração que pode ser vista abaixo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas, para realizar isso, primeiro foi necessário determinar critérios para a classificação:\n",
    "\n",
    "- Mencionar o produto;\n",
    "- A menção ao produto deve ser acompanhada de uma opinião;\n",
    "- A opinião pode ser demonstrada na forma de indagações, reclamações, pode envolver sarcasmo, elogios e sugestões sobre serviços;\n",
    "- A opinião afirmada deve ser clara;\n",
    "- Emoctions também representam opiniões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A quantidade de cada cada um é: \n",
      "\n",
      " Irrelevante    184\n",
      "Relevante      116\n",
      "Name: Relevância, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "mensagens = pd.read_excel(\"Nubank.xlsx\")\n",
    "mensagens.Relevância = mensagens.Relevância.astype('category')\n",
    "mensagens.Relevância.cat.categories = ('Irrelevante', 'Relevante')\n",
    "\n",
    "print(\"A quantidade de cada cada um é: \\n\\n\", mensagens.Relevância.value_counts())\n",
    "\n",
    "relevante = mensagens[mensagens.Relevância==\"Relevante\"]\n",
    "irrelevante = mensagens[mensagens.Relevância==\"Irrelevante\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Função que troca pontuação por espaço '''\n",
    "def cleanup(text):\n",
    "    punctuation = '[!\\-.:?;/,|@\"\\'()]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    # Abaixo, determina que se troca por espaço\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed\n",
    "\n",
    "# Usando a função apply para fazer a limpeza nas mensagens\n",
    "nubank_relev = relevante.Treinamento.apply(cleanup)\n",
    "nubank_irrelev = irrelevante.Treinamento.apply(cleanup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nubank            147\n",
      "o                  68\n",
      "de                 67\n",
      "e                  60\n",
      "que                60\n",
      "https              58\n",
      "t                  58\n",
      "co                 58\n",
      "a                  56\n",
      "não                52\n",
      "é                  38\n",
      "um                 36\n",
      "da                 33\n",
      "com                32\n",
      "do                 31\n",
      "eu                 30\n",
      "se                 30\n",
      "gente              29\n",
      "tem                28\n",
      "pra                26\n",
      "no                 25\n",
      "meu                25\n",
      "cartão             24\n",
      "em                 24\n",
      "na                 24\n",
      "você               23\n",
      "só                 22\n",
      "conta              22\n",
      "uma                22\n",
      "me                 19\n",
      "                 ... \n",
      "zq6cca3lv1          1\n",
      "d…e                 1\n",
      "todos               1\n",
      "vendi               1\n",
      "corre               1\n",
      "droga               1\n",
      "impressionada       1\n",
      "noçã…eu             1\n",
      "wj5ukyfgfv          1\n",
      "zma7gokeer          1\n",
      "experiência         1\n",
      "castrocastrado      1\n",
      "tranferi            1\n",
      "ifg                 1\n",
      "salve               1\n",
      "br                  1\n",
      "conferido           1\n",
      "fechei              1\n",
      "rwdhdtvvhe          1\n",
      "xz90obf2um          1\n",
      "delelista           1\n",
      "xoghmzchwg          1\n",
      "tmjrt               1\n",
      "bolinhas            1\n",
      "dessa               1\n",
      "amores              1\n",
      "endividar           1\n",
      "login               1\n",
      "wendhio10           1\n",
      "vazou               1\n",
      "Name: 0, Length: 1129, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Pegando as palavras em cada tópico: Relevante e Irrelevante\n",
    "\n",
    "words_relev = pd.DataFrame(\"\".join(nubank_relev).split())\n",
    "#print(words_relev[0].value_counts())\n",
    "\n",
    "\n",
    "words_irrelev = pd.DataFrame(\"\".join(nubank_irrelev).split())\n",
    "print(words_irrelev[0].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Frequência Absoluta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nubank            146\n",
       "o                  68\n",
       "de                 67\n",
       "e                  60\n",
       "que                60\n",
       "https              58\n",
       "t                  58\n",
       "co                 58\n",
       "a                  56\n",
       "não                52\n",
       "é                  38\n",
       "um                 36\n",
       "da                 33\n",
       "com                32\n",
       "do                 31\n",
       "se                 30\n",
       "eu                 29\n",
       "gente              29\n",
       "tem                28\n",
       "pra                26\n",
       "no                 25\n",
       "meu                25\n",
       "em                 23\n",
       "cartão             23\n",
       "na                 23\n",
       "você               23\n",
       "uma                22\n",
       "só                 22\n",
       "conta              22\n",
       "limite             19\n",
       "                 ... \n",
       "desistir            1\n",
       "hahahaha            1\n",
       "zma7gokeer          1\n",
       "virtual             1\n",
       "experiência         1\n",
       "primeiro            1\n",
       "castrocastrado      1\n",
       "tranferi            1\n",
       "ifg                 1\n",
       "salve               1\n",
       "br                  1\n",
       "conferido           1\n",
       "rwdhdtvvhe          1\n",
       "xz90obf2um          1\n",
       "delelista           1\n",
       "xoghmzchwg          1\n",
       "tmjrt               1\n",
       "bolinhas            1\n",
       "dessa               1\n",
       "início              1\n",
       "endividar           1\n",
       "login               1\n",
       "wendhio10           1\n",
       "fechei              1\n",
       "(coordenador        1\n",
       "vendi               1\n",
       "todos               1\n",
       "d…e                 1\n",
       "correios            1\n",
       "vazou               1\n",
       "Name: 0, Length: 1143, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_irrelev[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Frequência relativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nubank            0.053656\n",
       "o                 0.027066\n",
       "de                0.025641\n",
       "e                 0.024691\n",
       "que               0.021368\n",
       "eu                0.018044\n",
       "a                 0.016144\n",
       "me                0.013770\n",
       "https             0.013295\n",
       "co                0.013295\n",
       "meu               0.013295\n",
       "t                 0.013295\n",
       "um                0.012821\n",
       "não               0.012346\n",
       "é                 0.011871\n",
       "cartão            0.010921\n",
       "do                0.010921\n",
       "no                0.009497\n",
       "uma               0.007597\n",
       "pra               0.007123\n",
       "q                 0.007123\n",
       "na                0.007123\n",
       "com               0.006648\n",
       "só                0.006173\n",
       "limite            0.005698\n",
       "to                0.005698\n",
       "mais              0.005698\n",
       "nunca             0.005223\n",
       "tem               0.005223\n",
       "da                0.005223\n",
       "                    ...   \n",
       "né                0.000475\n",
       "odeio             0.000475\n",
       "estornou          0.000475\n",
       "lembrando         0.000475\n",
       "eveeeeer          0.000475\n",
       "ela               0.000475\n",
       "consegui          0.000475\n",
       "u                 0.000475\n",
       "indevidas         0.000475\n",
       "psqhd4ipep        0.000475\n",
       "castrocastrado    0.000475\n",
       "produto           0.000475\n",
       "500               0.000475\n",
       "expectativa       0.000475\n",
       "😍o                0.000475\n",
       "cheio             0.000475\n",
       "tt                0.000475\n",
       "renatojg          0.000475\n",
       "completar         0.000475\n",
       "somente           0.000475\n",
       "desativar         0.000475\n",
       "autorizasse       0.000475\n",
       "#nubank           0.000475\n",
       "pgzfiwma63        0.000475\n",
       "corre             0.000475\n",
       "lindo             0.000475\n",
       "gktnmnmi2y        0.000475\n",
       "ilfroes           0.000475\n",
       "bixo              0.000475\n",
       "vazou             0.000475\n",
       "Name: 0, Length: 850, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_relev[0].value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
