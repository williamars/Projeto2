{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nome**: Jonas da Silva Lopes\n",
    "\n",
    "**Nome**: William Silva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Classificador autom√°tico de sentimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "import re \n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***@William48253649***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Identificador da conta no twitter: @William48253649\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido\n",
    "produto = 'Nubank'\n",
    "\n",
    "#Quantidade m√≠nima de mensagens capturadas\n",
    "n = 500\n",
    "#Quantidade m√≠nima de mensagens para a base de treinamento\n",
    "t = 300\n",
    "\n",
    "#Filtro de l√≠ngua\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "    msgs.append(msg.full_text.lower()) #Lower para deixar tudo min√∫sculo e facilitar a compara√ß√£o\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um poss√≠vel vi√©s\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo n√£o existe para n√£o substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])}).set()\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])}).set()\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Ap√≥s realizar a classifica√ß√£o manual das mensagens, como irrelevante (0) ou relevante (1), partimos para  a mudan√ßa desses valores para algo mais palp√°vel para a an√°lise. Com isso, fazemos a altera√ß√£o que pode ser vista abaixo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas, para realizar isso, primeiro foi necess√°rio determinar crit√©rios para a classifica√ß√£o:\n",
    "\n",
    "- Mencionar o produto;\n",
    "- A men√ß√£o ao produto deve ser acompanhada de uma opini√£o;\n",
    "- A opini√£o pode ser demonstrada na forma de indaga√ß√µes, reclama√ß√µes, pode envolver sarcasmo, elogios e sugest√µes sobre servi√ßos;\n",
    "- A opini√£o afirmada deve ser clara;\n",
    "- Emoctions tamb√©m representam opini√µes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A quantidade de cada cada um √©: \n",
      "\n",
      " Irrelevante    184\n",
      "Relevante      116\n",
      "Name: Relev√¢ncia, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "mensagens = pd.read_excel(\"Nubank.xlsx\")\n",
    "mensagens.Relev√¢ncia = mensagens.Relev√¢ncia.astype('category')\n",
    "mensagens.Relev√¢ncia.cat.categories = ('Irrelevante', 'Relevante')\n",
    "\n",
    "print(\"A quantidade de cada cada um √©: \\n\\n\", mensagens.Relev√¢ncia.value_counts())\n",
    "\n",
    "relevante = mensagens[mensagens.Relev√¢ncia==\"Relevante\"]\n",
    "irrelevante = mensagens[mensagens.Relev√¢ncia==\"Irrelevante\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Fun√ß√£o que troca pontua√ß√£o por espa√ßo '''\n",
    "def cleanup(text):\n",
    "    punctuation = '[!\\-.:?;/,|@\"\\'()]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    # Abaixo, determina que se troca por espa√ßo\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed\n",
    "\n",
    "# Usando a fun√ß√£o apply para fazer a limpeza nas mensagens\n",
    "nubank_relev = relevante.Treinamento.apply(cleanup)\n",
    "nubank_irrelev = irrelevante.Treinamento.apply(cleanup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nubank            147\n",
      "o                  68\n",
      "de                 67\n",
      "e                  60\n",
      "que                60\n",
      "https              58\n",
      "t                  58\n",
      "co                 58\n",
      "a                  56\n",
      "n√£o                52\n",
      "√©                  38\n",
      "um                 36\n",
      "da                 33\n",
      "com                32\n",
      "do                 31\n",
      "eu                 30\n",
      "se                 30\n",
      "gente              29\n",
      "tem                28\n",
      "pra                26\n",
      "no                 25\n",
      "meu                25\n",
      "cart√£o             24\n",
      "em                 24\n",
      "na                 24\n",
      "voc√™               23\n",
      "s√≥                 22\n",
      "conta              22\n",
      "uma                22\n",
      "me                 19\n",
      "                 ... \n",
      "zq6cca3lv1          1\n",
      "d‚Ä¶e                 1\n",
      "todos               1\n",
      "vendi               1\n",
      "corre               1\n",
      "droga               1\n",
      "impressionada       1\n",
      "no√ß√£‚Ä¶eu             1\n",
      "wj5ukyfgfv          1\n",
      "zma7gokeer          1\n",
      "experi√™ncia         1\n",
      "castrocastrado      1\n",
      "tranferi            1\n",
      "ifg                 1\n",
      "salve               1\n",
      "br                  1\n",
      "conferido           1\n",
      "fechei              1\n",
      "rwdhdtvvhe          1\n",
      "xz90obf2um          1\n",
      "delelista           1\n",
      "xoghmzchwg          1\n",
      "tmjrt               1\n",
      "bolinhas            1\n",
      "dessa               1\n",
      "amores              1\n",
      "endividar           1\n",
      "login               1\n",
      "wendhio10           1\n",
      "vazou               1\n",
      "Name: 0, Length: 1129, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Pegando as palavras em cada t√≥pico: Relevante e Irrelevante\n",
    "\n",
    "words_relev = pd.DataFrame(\"\".join(nubank_relev).split())\n",
    "#print(words_relev[0].value_counts())\n",
    "\n",
    "\n",
    "words_irrelev = pd.DataFrame(\"\".join(nubank_irrelev).split())\n",
    "print(words_irrelev[0].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Frequ√™ncia Absoluta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nubank            146\n",
       "o                  68\n",
       "de                 67\n",
       "e                  60\n",
       "que                60\n",
       "https              58\n",
       "t                  58\n",
       "co                 58\n",
       "a                  56\n",
       "n√£o                52\n",
       "√©                  38\n",
       "um                 36\n",
       "da                 33\n",
       "com                32\n",
       "do                 31\n",
       "se                 30\n",
       "eu                 29\n",
       "gente              29\n",
       "tem                28\n",
       "pra                26\n",
       "no                 25\n",
       "meu                25\n",
       "em                 23\n",
       "cart√£o             23\n",
       "na                 23\n",
       "voc√™               23\n",
       "uma                22\n",
       "s√≥                 22\n",
       "conta              22\n",
       "limite             19\n",
       "                 ... \n",
       "desistir            1\n",
       "hahahaha            1\n",
       "zma7gokeer          1\n",
       "virtual             1\n",
       "experi√™ncia         1\n",
       "primeiro            1\n",
       "castrocastrado      1\n",
       "tranferi            1\n",
       "ifg                 1\n",
       "salve               1\n",
       "br                  1\n",
       "conferido           1\n",
       "rwdhdtvvhe          1\n",
       "xz90obf2um          1\n",
       "delelista           1\n",
       "xoghmzchwg          1\n",
       "tmjrt               1\n",
       "bolinhas            1\n",
       "dessa               1\n",
       "in√≠cio              1\n",
       "endividar           1\n",
       "login               1\n",
       "wendhio10           1\n",
       "fechei              1\n",
       "(coordenador        1\n",
       "vendi               1\n",
       "todos               1\n",
       "d‚Ä¶e                 1\n",
       "correios            1\n",
       "vazou               1\n",
       "Name: 0, Length: 1143, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_irrelev[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Frequ√™ncia relativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nubank            0.053656\n",
       "o                 0.027066\n",
       "de                0.025641\n",
       "e                 0.024691\n",
       "que               0.021368\n",
       "eu                0.018044\n",
       "a                 0.016144\n",
       "me                0.013770\n",
       "https             0.013295\n",
       "co                0.013295\n",
       "meu               0.013295\n",
       "t                 0.013295\n",
       "um                0.012821\n",
       "n√£o               0.012346\n",
       "√©                 0.011871\n",
       "cart√£o            0.010921\n",
       "do                0.010921\n",
       "no                0.009497\n",
       "uma               0.007597\n",
       "pra               0.007123\n",
       "q                 0.007123\n",
       "na                0.007123\n",
       "com               0.006648\n",
       "s√≥                0.006173\n",
       "limite            0.005698\n",
       "to                0.005698\n",
       "mais              0.005698\n",
       "nunca             0.005223\n",
       "tem               0.005223\n",
       "da                0.005223\n",
       "                    ...   \n",
       "n√©                0.000475\n",
       "odeio             0.000475\n",
       "estornou          0.000475\n",
       "lembrando         0.000475\n",
       "eveeeeer          0.000475\n",
       "ela               0.000475\n",
       "consegui          0.000475\n",
       "u                 0.000475\n",
       "indevidas         0.000475\n",
       "psqhd4ipep        0.000475\n",
       "castrocastrado    0.000475\n",
       "produto           0.000475\n",
       "500               0.000475\n",
       "expectativa       0.000475\n",
       "üòço                0.000475\n",
       "cheio             0.000475\n",
       "tt                0.000475\n",
       "renatojg          0.000475\n",
       "completar         0.000475\n",
       "somente           0.000475\n",
       "desativar         0.000475\n",
       "autorizasse       0.000475\n",
       "#nubank           0.000475\n",
       "pgzfiwma63        0.000475\n",
       "corre             0.000475\n",
       "lindo             0.000475\n",
       "gktnmnmi2y        0.000475\n",
       "ilfroes           0.000475\n",
       "bixo              0.000475\n",
       "vazou             0.000475\n",
       "Name: 0, Length: 850, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_relev[0].value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza an√°lise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
