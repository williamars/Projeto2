{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nome**: Jonas da Silva Lopes\n",
    "\n",
    "**Nome**: William Silva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Classificador autom√°tico de sentimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install tweepy\n",
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import emoji\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "import re \n",
    "import functools\n",
    "import operator\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***@William48253649***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Identificador da conta no twitter: @William48253649\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido\n",
    "produto = 'Nubank'\n",
    "\n",
    "#Quantidade m√≠nima de mensagens capturadas\n",
    "n = 500\n",
    "#Quantidade m√≠nima de mensagens para a base de treinamento\n",
    "t = 300\n",
    "\n",
    "#Filtro de l√≠ngua\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "    msgs.append(msg.full_text.lower()) #Lower para deixar tudo min√∫sculo e facilitar a compara√ß√£o\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um poss√≠vel vi√©s\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo n√£o existe para n√£o substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])}).set()\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])}).set()\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Ap√≥s realizar a classifica√ß√£o manual das mensagens, como irrelevante (0) ou relevante (1), partimos para  a mudan√ßa desses valores para algo mais palp√°vel para a an√°lise. Com isso, fazemos a altera√ß√£o que pode ser vista abaixo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas, para realizar isso, primeiro foi necess√°rio determinar crit√©rios para a classifica√ß√£o:\n",
    "\n",
    "- Mencionar o produto;\n",
    "- A men√ß√£o ao produto deve ser acompanhada de uma opini√£o;\n",
    "- A opini√£o pode ser demonstrada na forma de indaga√ß√µes, reclama√ß√µes, pode envolver sarcasmo, elogios e sugest√µes sobre servi√ßos;\n",
    "- A opini√£o afirmada deve ser clara;\n",
    "- Emoctions tamb√©m representam opini√µes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A quantidade de cada cada um √©: \n",
      "\n",
      " Irrelevante    184\n",
      "Relevante      116\n",
      "Name: Relev√¢ncia, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mensagens = pd.read_excel(\"Nubank.xlsx\")\n",
    "mensagens.Relev√¢ncia = mensagens.Relev√¢ncia.astype('category')\n",
    "mensagens.Relev√¢ncia.cat.categories = ('Irrelevante', 'Relevante')\n",
    "\n",
    "print(\"A quantidade de cada cada um √©: \\n\\n\", mensagens.Relev√¢ncia.value_counts())\n",
    "\n",
    "relevante = mensagens[mensagens.Relev√¢ncia==\"Relevante\"]\n",
    "irrelevante = mensagens[mensagens.Relev√¢ncia==\"Irrelevante\"]\n",
    "\n",
    "len(mensagens.Relev√¢ncia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-26e59bfd84d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mlista_nubank_relev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlista\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mlista_nubank_relev\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\Nova pasta\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   4374\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4375\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4376\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4378\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'type'"
     ]
    }
   ],
   "source": [
    "''' Fun√ß√£o que troca pontua√ß√£o por espa√ßo '''\n",
    "def cleanup(text):\n",
    "    punctuation = '[!\\-.:?;/,|@\"\\'()]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    # Abaixo, determina que se troca por espa√ßo\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    \n",
    "    emoji_dividir = emoji.get_emoji_regexp().split(text_subbed)\n",
    "    espaco_dividir = [substr.split() for substr in emoji_dividir]\n",
    "    split = functools.reduce(operator.concat, espaco_dividir)\n",
    "    \n",
    "    return split\n",
    "\n",
    "# Usando a fun√ß√£o apply para fazer a limpeza nas mensagens\n",
    "nubank_relev = relevante.Treinamento.apply(cleanup)\n",
    "nubank_irrelev = irrelevante.Treinamento.apply(cleanup)\n",
    "\n",
    "\n",
    "lista = []\n",
    "i = 0\n",
    "for linha in nubank_relev:\n",
    "    while i < len(linha):\n",
    "        lista.append(linha[i])\n",
    "        i += 1\n",
    "    i = 0\n",
    "    \n",
    "lista_nubank_relev = pd.DataFrame(lista) \n",
    "lista_nubank_relev[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, int found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-c8dbbad90c97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Pegando as palavras em cada t√≥pico: Relevante e Irrelevante\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mwords_relev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlista_nubank_relev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mwords_irrelev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnubank_irrelev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: sequence item 0: expected str instance, int found"
     ]
    }
   ],
   "source": [
    "# Pegando as palavras em cada t√≥pico: Relevante e Irrelevante\n",
    "words_relev = pd.DataFrame(''.join(lista_nubank_relev))\n",
    "\n",
    "\n",
    "words_irrelev = pd.DataFrame(\"\".join(nubank_irrelev).split())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Frequ√™ncia Absoluta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Frequ√™ncia relativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words_relev[0].value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nubank': 122,\n",
       " 'o': 58,\n",
       " 'de': 54,\n",
       " 'e': 52,\n",
       " 'eu': 47,\n",
       " 'que': 45,\n",
       " 'a': 35,\n",
       " 'meu': 34,\n",
       " 'me': 29,\n",
       " 't': 28,\n",
       " 'co': 28,\n",
       " 'https': 28,\n",
       " 'um': 27,\n",
       " 'n√£o': 26,\n",
       " '√©': 25,\n",
       " 'cart√£o': 23,\n",
       " 'do': 23,\n",
       " 'no': 20,\n",
       " 'uma': 16,\n",
       " 'na': 15,\n",
       " 'q': 15,\n",
       " 'pra': 15,\n",
       " 'to': 14,\n",
       " 'com': 14,\n",
       " 's√≥': 13,\n",
       " 'limite': 12,\n",
       " 'mais': 12,\n",
       " 'da': 11,\n",
       " 'nunca': 11,\n",
       " 'tem': 11,\n",
       " 'j√°': 10,\n",
       " 'por': 10,\n",
       " 'isso': 9,\n",
       " 'foi': 9,\n",
       " 'dia': 9,\n",
       " 'vou': 8,\n",
       " 'ai': 8,\n",
       " 'se': 8,\n",
       " 'minha': 8,\n",
       " 'mas': 8,\n",
       " 'eles': 8,\n",
       " 'banco': 7,\n",
       " 'pelo': 7,\n",
       " 'üòç': 7,\n",
       " 'chegou': 7,\n",
       " 'em': 7,\n",
       " 'nada': 7,\n",
       " 'aceita': 6,\n",
       " 'cr√©dito': 6,\n",
       " 'assim': 6,\n",
       " 'app': 6,\n",
       " 'te': 6,\n",
       " 'pro': 6,\n",
       " '‚ù§': 6,\n",
       " 'gente': 6,\n",
       " 'conta': 6,\n",
       " 'toda': 6,\n",
       " 'mesmo': 6,\n",
       " 'os': 6,\n",
       " 'ser': 5,\n",
       " 't√¥': 5,\n",
       " 'ele': 5,\n",
       " 'hora': 5,\n",
       " 'Ô∏è': 5,\n",
       " 'fui': 5,\n",
       " 'quando': 5,\n",
       " 'amo': 5,\n",
       " 'aqui': 5,\n",
       " 'üíú': 5,\n",
       " 'ainda': 5,\n",
       " 'a√≠': 5,\n",
       " 'p': 5,\n",
       " 'estou': 5,\n",
       " 'ta': 5,\n",
       " 'esse': 5,\n",
       " 'nem': 5,\n",
       " 'clonado': 5,\n",
       " 'quero': 4,\n",
       " 'usar': 4,\n",
       " 'reais': 4,\n",
       " 'essa': 4,\n",
       " 'cart√µes': 4,\n",
       " 'fatura': 4,\n",
       " 'triste': 4,\n",
       " 'aumenta': 4,\n",
       " 't√°': 4,\n",
       " 'tenho': 4,\n",
       " 'demais': 4,\n",
       " 'fazer': 4,\n",
       " 'm√™s': 4,\n",
       " '1masterball': 4,\n",
       " 'esperando': 4,\n",
       " 'muito': 4,\n",
       " 'meus': 4,\n",
       " 'problema': 4,\n",
       " 'anos': 4,\n",
       " 'agora': 4,\n",
       " 'tanto': 4,\n",
       " 'voc√™s': 4,\n",
       " 'porque': 4,\n",
       " 'desde': 4,\n",
       " 'obrigado': 4,\n",
       " 'tudo': 3,\n",
       " 'melhor': 3,\n",
       " 's√£o': 3,\n",
       " 'pedir': 3,\n",
       " 'as': 3,\n",
       " 'ter': 3,\n",
       " 'feliz': 3,\n",
       " 'mundo': 3,\n",
       " 'mimo': 3,\n",
       " 'obrigada': 3,\n",
       " 'veio': 3,\n",
       " 'libera': 3,\n",
       " 'nossa': 3,\n",
       " 'vai': 3,\n",
       " 'compras': 3,\n",
       " 'atendimento': 3,\n",
       " 'maior': 3,\n",
       " '50': 3,\n",
       " 'como': 3,\n",
       " 'pegar': 3,\n",
       " 'ficar': 3,\n",
       " 'l√°': 3,\n",
       " 'roxinho': 3,\n",
       " 'seu': 3,\n",
       " 'deus': 3,\n",
       " '#sounu': 3,\n",
       " 'quer': 3,\n",
       " 'preciso': 3,\n",
       " 'ent√£o': 3,\n",
       " 'depois': 3,\n",
       " 'todo': 3,\n",
       " 'tentando': 3,\n",
       " 'next': 3,\n",
       " 'finalmente': 3,\n",
       " 'cada': 3,\n",
       " 'fiz': 3,\n",
       " 'novo': 3,\n",
       " 'tinha': 3,\n",
       " 'pqp': 3,\n",
       " 'rindo': 3,\n",
       " 'ano': 3,\n",
       " 'hein': 3,\n",
       " 'empr√©stimo': 2,\n",
       " 'bancos': 2,\n",
       " 'msm': 2,\n",
       " 'nojo': 2,\n",
       " 'forma': 2,\n",
       " '2': 2,\n",
       " 'medo': 2,\n",
       " 'amigo': 2,\n",
       " 'pedi': 2,\n",
       " 'dar': 2,\n",
       " 'comigo': 2,\n",
       " 'compra': 2,\n",
       " 'alta': 2,\n",
       " 'jesus': 2,\n",
       " 'üò≠': 2,\n",
       " 'at√©': 2,\n",
       " 'bloqueio': 2,\n",
       " 'comprar': 2,\n",
       " 'livre': 2,\n",
       " 'tentar': 2,\n",
       " 'dele': 2,\n",
       " 'tava': 2,\n",
       " 'ama': 2,\n",
       " 'uso': 2,\n",
       " 'menina': 2,\n",
       " 'favor': 2,\n",
       " 'hoje': 2,\n",
       " 'cartao': 2,\n",
       " 'deles': 2,\n",
       " 'cliente': 2,\n",
       " 'bloqueado': 2,\n",
       " 'mal': 2,\n",
       " 'porra': 2,\n",
       " 'desbloqueio': 2,\n",
       " 'd√©bito': 2,\n",
       " 'preju√≠zo': 2,\n",
       " 'quem': 2,\n",
       " 'para': 2,\n",
       " 'pai': 2,\n",
       " 'vida': 2,\n",
       " 'puta': 2,\n",
       " 'queria': 2,\n",
       " 'espero': 2,\n",
       " 'todas': 2,\n",
       " 'agr': 2,\n",
       " 'nervoso': 2,\n",
       " 'sabia': 2,\n",
       " 'ir': 2,\n",
       " 'n': 2,\n",
       " 'aprovado': 2,\n",
       " '3': 2,\n",
       " 'sou': 2,\n",
       " 'f√°cil': 2,\n",
       " 'rt': 2,\n",
       " 'bloquear': 2,\n",
       " 'deu': 2,\n",
       " 'aceitou': 2,\n",
       " 'achei': 2,\n",
       " 'ao': 2,\n",
       " 'haunted_electra': 2,\n",
       " 'preocupada': 2,\n",
       " 'mandei': 2,\n",
       " 'bixo': 2,\n",
       " 'dona': 2,\n",
       " 'capitalismo': 2,\n",
       " 'ü§™': 2,\n",
       " 'faz': 2,\n",
       " 'cansada': 2,\n",
       " '__chicao__': 2,\n",
       " '√∫nica': 2,\n",
       " 'coisa': 2,\n",
       " 'cancelar': 2,\n",
       " 'rafaelmachado94': 2,\n",
       " 'fiquei': 2,\n",
       " 'conversa': 2,\n",
       " 'pessoa': 2,\n",
       " 'gtcarvalh0': 2,\n",
       " 'liberou': 2,\n",
       " 'essas': 2,\n",
       " 'tive': 2,\n",
       " 'rs': 2,\n",
       " 'cancelei': 2,\n",
       " 'super': 2,\n",
       " 'negrote__': 2,\n",
       " 'liberam': 2,\n",
       " 'bem': 2,\n",
       " 'aprovada': 2,\n",
       " 'pq': 2,\n",
       " 'pagar': 2,\n",
       " 'aconteceu': 2,\n",
       " 'convite': 2,\n",
       " 'minhas': 2,\n",
       " '1': 2,\n",
       " 'vc': 2,\n",
       " 'sim': 2,\n",
       " 'ansiosa': 2,\n",
       " 'parece': 2,\n",
       " 'perguntei': 2,\n",
       " 'coma': 1,\n",
       " 'kzi2obkz2f': 1,\n",
       " 'diante': 1,\n",
       " 'for√ßas': 1,\n",
       " 'enxoval': 1,\n",
       " '1sfwbsyb50': 1,\n",
       " 'üòé': 1,\n",
       " 'agressiva': 1,\n",
       " 'roubar': 1,\n",
       " 'volta': 1,\n",
       " 'opsaboob': 1,\n",
       " 'desses': 1,\n",
       " 'üòî': 1,\n",
       " 'per√≠odo': 1,\n",
       " 'loka': 1,\n",
       " 'clonaram': 1,\n",
       " 'sempre': 1,\n",
       " 'urgentemente': 1,\n",
       " 'nenhum': 1,\n",
       " 'op√ß√£o': 1,\n",
       " 'pouco': 1,\n",
       " 'mo√ßo': 1,\n",
       " 'bichas': 1,\n",
       " 'psqhd4ipep': 1,\n",
       " 'convenci': 1,\n",
       " 'passar': 1,\n",
       " 'decep√ß√£o': 1,\n",
       " 'pois': 1,\n",
       " 'epis√≥dio': 1,\n",
       " 'mimos': 1,\n",
       " 'expectativa': 1,\n",
       " 'curioso': 1,\n",
       " '350': 1,\n",
       " 'perdi': 1,\n",
       " 'orgulhoso': 1,\n",
       " 'frustado': 1,\n",
       " 'crystal': 1,\n",
       " 'quiser': 1,\n",
       " 'üò±': 1,\n",
       " 'estourar': 1,\n",
       " '6': 1,\n",
       " 'abra√ßo': 1,\n",
       " 'completo': 1,\n",
       " 'larikaliane': 1,\n",
       " 'castrocastrado': 1,\n",
       " 'nildemoraes': 1,\n",
       " 'felizmente': 1,\n",
       " 'felizinha': 1,\n",
       " 'casos': 1,\n",
       " 'menos': 1,\n",
       " 'pediram': 1,\n",
       " 'f√≠sico': 1,\n",
       " 'valeriaales': 1,\n",
       " 'odeia': 1,\n",
       " 'brasil': 1,\n",
       " 'trata': 1,\n",
       " 'manda': 1,\n",
       " 'negocinho=3+horas': 1,\n",
       " 'buscar': 1,\n",
       " 'segundo': 1,\n",
       " 'help': 1,\n",
       " 'fosse': 1,\n",
       " 'viu': 1,\n",
       " 'vcs': 1,\n",
       " 'euzinha': 1,\n",
       " 'blindadah': 1,\n",
       " 'relato': 1,\n",
       " 'sxcxzejkab': 1,\n",
       " 'in√≠cio': 1,\n",
       " 'ü§¶\\u200d‚ôÇÔ∏è': 1,\n",
       " 'gritando': 1,\n",
       " 'logo': 1,\n",
       " 'final': 1,\n",
       " 'olha': 1,\n",
       " 'absolutamente': 1,\n",
       " 'entrei': 1,\n",
       " 'bolsa': 1,\n",
       " 'seguran√ßa': 1,\n",
       " 'falarem': 1,\n",
       " 'ruim': 1,\n",
       " 'fora': 1,\n",
       " 'vendas': 1,\n",
       " 'meio': 1,\n",
       " 'estranho': 1,\n",
       " 'td': 1,\n",
       " 'ag': 1,\n",
       " 'dados': 1,\n",
       " 'diferenciais': 1,\n",
       " 'r$': 1,\n",
       " '100': 1,\n",
       " 'rrpb89yes9': 1,\n",
       " 'terei': 1,\n",
       " 'chegar': 1,\n",
       " 'consegui': 1,\n",
       " 'impossivel': 1,\n",
       " 'anterior': 1,\n",
       " 'maluulana': 1,\n",
       " 'bah': 1,\n",
       " 'ü§Ø': 1,\n",
       " 'amor': 1,\n",
       " 'dando': 1,\n",
       " '02': 1,\n",
       " 'demoraram': 1,\n",
       " 'possibilidade': 1,\n",
       " 'üíò': 1,\n",
       " 'produto': 1,\n",
       " 'santa': 1,\n",
       " 'deixar': 1,\n",
       " 'fila': 1,\n",
       " 'foda': 1,\n",
       " 'silva': 1,\n",
       " 'ia': 1,\n",
       " 'ajuda': 1,\n",
       " 'tela': 1,\n",
       " 'defeito': 1,\n",
       " 'quittonog': 1,\n",
       " 'bus√£o': 1,\n",
       " 'somente': 1,\n",
       " 's√©rio': 1,\n",
       " 'n√≥s': 1,\n",
       " 'nao': 1,\n",
       " 'apareceu': 1,\n",
       " '4av08gusbn': 1,\n",
       " 'incondicionalmente': 1,\n",
       " '2015': 1,\n",
       " 'liberar': 1,\n",
       " 'declaro': 1,\n",
       " 'deste': 1,\n",
       " 'maioridade': 1,\n",
       " 'qual': 1,\n",
       " 'gold': 1,\n",
       " 'febre': 1,\n",
       " 'cama': 1,\n",
       " 'paizinho': 1,\n",
       " '#nucontapj': 1,\n",
       " 'humilhando': 1,\n",
       " 'f√°ceis': 1,\n",
       " 'auge': 1,\n",
       " 'virtual': 1,\n",
       " 'robzgf': 1,\n",
       " 'chega': 1,\n",
       " 'compraram': 1,\n",
       " 'todos': 1,\n",
       " 'luke_viei': 1,\n",
       " 'indico': 1,\n",
       " 'facilidade': 1,\n",
       " 'u': 1,\n",
       " 'tu': 1,\n",
       " 'caralho': 1,\n",
       " 'gabriel': 1,\n",
       " 'lucasafoliveira': 1,\n",
       " 'precisei': 1,\n",
       " 'desativar': 1,\n",
       " 'incr√≠vel': 1,\n",
       " 'eterna': 1,\n",
       " 'grande': 1,\n",
       " 'tamb√©m': 1,\n",
       " 'momento': 1,\n",
       " 'clonar': 1,\n",
       " 'percebo': 1,\n",
       " 'coloquei': 1,\n",
       " 'p√∫blico': 1,\n",
       " 'cora√ß√£o': 1,\n",
       " 'fofos': 1,\n",
       " 'vantagens': 1,\n",
       " 'cr': 1,\n",
       " 'verdade': 1,\n",
       " 'matar': 1,\n",
       " 'fechamento': 1,\n",
       " 'pianoetlux': 1,\n",
       " 'pj': 1,\n",
       " 'pega': 1,\n",
       " 'odeio': 1,\n",
       " 'cacha√ßa': 1,\n",
       " 'privada': 1,\n",
       " 'kkk': 1,\n",
       " 'dado': 1,\n",
       " 'inferno': 1,\n",
       " 'usando': 1,\n",
       " '392': 1,\n",
       " 'porras': 1,\n",
       " 'meuuuuuuu': 1,\n",
       " 'voltado': 1,\n",
       " 'cancelamento': 1,\n",
       " 'ahsgdj': 1,\n",
       " 'entrega': 1,\n",
       " 'pariu': 1,\n",
       " 'y8ljlcir6d': 1,\n",
       " 'dgianygarcia': 1,\n",
       " 'bombas': 1,\n",
       " 'credito': 1,\n",
       " 'pay': 1,\n",
       " 'buc*ta': 1,\n",
       " 'davam': 1,\n",
       " 'sensacional': 1,\n",
       " 'nome': 1,\n",
       " 'rodrigoag': 1,\n",
       " 'kkkkkk': 1,\n",
       " 'marialmeida93': 1,\n",
       " 'lan√ßar': 1,\n",
       " 'relata': 1,\n",
       " 'wolbshacdn': 1,\n",
       " 'aguardando': 1,\n",
       " 'n√©': 1,\n",
       " 'objetivo': 1,\n",
       " 'rec√©m': 1,\n",
       " 'fato': 1,\n",
       " 'cfo': 1,\n",
       " 'pagar√°': 1,\n",
       " 'assustada': 1,\n",
       " 'inclusive': 1,\n",
       " 'inicial': 1,\n",
       " 'dela': 1,\n",
       " 'lana': 1,\n",
       " 'fnlwvorvan': 1,\n",
       " 'gastei': 1,\n",
       " 'pobre': 1,\n",
       " 'ne': 1,\n",
       " 'af': 1,\n",
       " 'deixo': 1,\n",
       " 'case': 1,\n",
       " 'olhando': 1,\n",
       " 'sorte': 1,\n",
       " 'lanaalmeidaofc': 1,\n",
       " 'pufavozinho': 1,\n",
       " 'ü•∞': 1,\n",
       " 'r√°pido': 1,\n",
       " 'm√≥': 1,\n",
       " 'espera': 1,\n",
       " 'jo√£o': 1,\n",
       " 'acho': 1,\n",
       " 'simplesmente': 1,\n",
       " 'decepciona': 1,\n",
       " 'computador': 1,\n",
       " 'enquanto': 1,\n",
       " 'itaucard': 1,\n",
       " 'outros': 1,\n",
       " 'comprovava': 1,\n",
       " 'lembrei': 1,\n",
       " 'queridos': 1,\n",
       " 'ü§ó': 1,\n",
       " 'corre': 1,\n",
       " 'ifovvyngg9': 1,\n",
       " 'perder': 1,\n",
       " 'sites': 1,\n",
       " 'resolver': 1,\n",
       " 'ningu√©m': 1,\n",
       " 'email': 1,\n",
       " 'clonados': 1,\n",
       " 'atinjo': 1,\n",
       " 'est√°': 1,\n",
       " 'paga': 1,\n",
       " 'rappibrasil': 1,\n",
       " 'colocando': 1,\n",
       " 'suas': 1,\n",
       " 'existe': 1,\n",
       " 'facebook': 1,\n",
       " 'seria': 1,\n",
       " 'elabora√ß√£o': 1,\n",
       " 'ela': 1,\n",
       " 'passo': 1,\n",
       " 'mabzinhaa': 1,\n",
       " 'nubankinho': 1,\n",
       " 'fechar': 1,\n",
       " 'ser√°': 1,\n",
       " 'completar': 1,\n",
       " 'pgzfiwma63': 1,\n",
       " 'tempo': 1,\n",
       " 'daqui': 1,\n",
       " '12': 1,\n",
       " 'eita': 1,\n",
       " 'tradicionais': 1,\n",
       " 'ddrzmw0zub': 1,\n",
       " 'pfvr': 1,\n",
       " 'anrskj6lst': 1,\n",
       " 'tempor√°ria': 1,\n",
       " 'duas': 1,\n",
       " 'bb': 1,\n",
       " 'algu√©m': 1,\n",
       " 'desisto': 1,\n",
       " '√≠ndia': 1,\n",
       " 'kkkkk': 1,\n",
       " '8g4j8hznpd': 1,\n",
       " 'chance': 1,\n",
       " 'tal': 1,\n",
       " 'disse': 1,\n",
       " 'mano': 1,\n",
       " 'imaginar': 1,\n",
       " 'renda': 1,\n",
       " 'imaginou': 1,\n",
       " 'ver': 1,\n",
       " 'neeeee': 1,\n",
       " 'kimgjiwon': 1,\n",
       " 'ajustar': 1,\n",
       " 'correndo': 1,\n",
       " 'pedindo': 1,\n",
       " 'resposta': 1,\n",
       " 'autom√°tica': 1,\n",
       " 'p√°': 1,\n",
       " 'foto': 1,\n",
       " 'trabalhar': 1,\n",
       " 'p√≥s': 1,\n",
       " 'megera': 1,\n",
       " 'recebemos': 1,\n",
       " 'vivem': 1,\n",
       " 'grandes': 1,\n",
       " 'expectativas': 1,\n",
       " 'outro': 1,\n",
       " 'vivia': 1,\n",
       " 'durante': 1,\n",
       " 'mandasse': 1,\n",
       " 'design': 1,\n",
       " 'atendida': 1,\n",
       " 'salvou': 1,\n",
       " 'arruma': 1,\n",
       " 'celular': 1,\n",
       " 'fada': 1,\n",
       " 'fal√™ncia': 1,\n",
       " 'vi': 1,\n",
       " 'lembrando': 1,\n",
       " 'fun√ß√£o': 1,\n",
       " 'conseguir': 1,\n",
       " 'ads': 1,\n",
       " 'üò¢': 1,\n",
       " 'rapidinho': 1,\n",
       " 'üòå': 1,\n",
       " 'c': 1,\n",
       " 'norvana': 1,\n",
       " 'piso': 1,\n",
       " 'propaganda': 1,\n",
       " 'nenhuma': 1,\n",
       " 'voltar': 1,\n",
       " 'carregar': 1,\n",
       " 'to6j46gsrr': 1,\n",
       " 'hauahuah': 1,\n",
       " 'critiquei': 1,\n",
       " 'perdida': 1,\n",
       " 'contas': 1,\n",
       " 'coisas': 1,\n",
       " 'deveria': 1,\n",
       " 'cu': 1,\n",
       " 'querendo': 1,\n",
       " 'passou': 1,\n",
       " 'zcmtre7wrg': 1,\n",
       " 'acometendo': 1,\n",
       " 'robertoper3ir4': 1,\n",
       " 'vezes': 1,\n",
       " 'nandoida': 1,\n",
       " 'dava': 1,\n",
       " 'afropreticinha': 1,\n",
       " 'fluxo': 1,\n",
       " 'issk': 1,\n",
       " 'acontecido': 1,\n",
       " 'pavor': 1,\n",
       " 'pud√©ssemos': 1,\n",
       " 'üôèüèæ': 1,\n",
       " 'jbwrdopgts': 1,\n",
       " 'ow': 1,\n",
       " 'eveeeeer': 1,\n",
       " 'anuidade': 1,\n",
       " '4k': 1,\n",
       " 'autorizasse': 1,\n",
       " 'nos': 1,\n",
       " 'atrav√©s': 1,\n",
       " 'gv8e5dmb70': 1,\n",
       " 'casar': 1,\n",
       " 'passei': 1,\n",
       " 'outras': 1,\n",
       " 'posta': 1,\n",
       " 'estorno': 1,\n",
       " 'for': 1,\n",
       " 'mana': 1,\n",
       " 'i': 1,\n",
       " 'valor': 1,\n",
       " 'lindo': 1,\n",
       " 'c6': 1,\n",
       " 'meta': 1,\n",
       " 'clientes': 1,\n",
       " 'crian√ßa': 1,\n",
       " 'ganhou': 1,\n",
       " 'm√≠nimo': 1,\n",
       " 'indevidas': 1,\n",
       " 'fa√ßo': 1,\n",
       " 'loja': 1,\n",
       " '#nuconta': 1,\n",
       " 'belo': 1,\n",
       " 'kakakakakakkak': 1,\n",
       " 'futebol': 1,\n",
       " 'vamo': 1,\n",
       " 'gem': 1,\n",
       " 'melhorar': 1,\n",
       " 'uns': 1,\n",
       " 'equipe': 1,\n",
       " 'diz': 1,\n",
       " 'representa': 1,\n",
       " 'trava': 1,\n",
       " 'livramento': 1,\n",
       " '0b3igvmynt': 1,\n",
       " 'hj': 1,\n",
       " 'tentaram': 1,\n",
       " 'eocotta': 1,\n",
       " 'geovana': 1,\n",
       " 'quase': 1,\n",
       " 'renatojg': 1,\n",
       " 'dao': 1,\n",
       " 'pequena': 1,\n",
       " 'pena': 1,\n",
       " 'pornos': 1,\n",
       " 'metas': 1,\n",
       " 'inv√©s': 1,\n",
       " 'sobre': 1,\n",
       " 'estornar': 1,\n",
       " 'conto': 1,\n",
       " 'anjo': 1,\n",
       " 'mesma': 1,\n",
       " 'digitais': 1,\n",
       " 'cmg': 1,\n",
       " 'tira': 1,\n",
       " 'apontam': 1,\n",
       " 'somei': 1,\n",
       " 'disso': 1,\n",
       " 'pr√≥prios': 1,\n",
       " 'anoja': 1,\n",
       " 'excluir': 1,\n",
       " '13k': 1,\n",
       " 'aprovaram': 1,\n",
       " 'paci√™ncia': 1,\n",
       " 'estava': 1,\n",
       " 'mim': 1,\n",
       " 'samba': 1,\n",
       " 'desse': 1,\n",
       " 'querido': 1,\n",
       " 'fizeram': 1,\n",
       " 'contar': 1,\n",
       " 'wan2gatnav': 1,\n",
       " 'resolve': 1,\n",
       " 'endividar': 1,\n",
       " 'aw7q7lciim': 1,\n",
       " 'yirpjs01lz': 1,\n",
       " 'h√°': 1,\n",
       " 'segura': 1,\n",
       " 'aprovou': 1,\n",
       " 'capinha': 1,\n",
       " 'funcion√°rios': 1,\n",
       " 'falhe': 1,\n",
       " 'hate': 1,\n",
       " 'sendo': 1,\n",
       " 'precisa': 1,\n",
       " 'thaioliv_': 1,\n",
       " 'princ√≠pio': 1,\n",
       " 'mail': 1,\n",
       " 'amadinha': 1,\n",
       " '17': 1,\n",
       " 'helogb__': 1,\n",
       " 'imensa': 1,\n",
       " 'vejo': 1,\n",
       " '6oa9amfuta': 1,\n",
       " 'contos': 1,\n",
       " 'almo√ßo': 1,\n",
       " 'lot√©rica': 1,\n",
       " 'amorosa': 1,\n",
       " 'aff': 1,\n",
       " 'falir': 1,\n",
       " 'jovem': 1,\n",
       " 'tao': 1,\n",
       " 'atrasei': 1,\n",
       " 'almeida': 1,\n",
       " 'aceitouuu': 1,\n",
       " 'deux': 1,\n",
       " 'nuconta': 1,\n",
       " 'hzkkfbefv3': 1,\n",
       " 'estornou': 1,\n",
       " 'melhores': 1,\n",
       " 'dias': 1,\n",
       " 'previd√™ncia': 1,\n",
       " 'gktnmnmi2y': 1,\n",
       " 'bancodobrasil': 1,\n",
       " '#nubank': 1,\n",
       " 'cheio': 1,\n",
       " 'vos': 1,\n",
       " 'ninguem': 1,\n",
       " '15': 1,\n",
       " 'desconfiei': 1,\n",
       " 'yasuqh': 1,\n",
       " 'antes': 1,\n",
       " 'visto': 1,\n",
       " 'aguento': 1,\n",
       " 'umas': 1,\n",
       " 'falar': 1,\n",
       " 'integra√ß√£o': 1,\n",
       " 'bom': 1,\n",
       " 'üòÇ': 1,\n",
       " 'deixasse': 1,\n",
       " 'assusta': 1,\n",
       " 'testar': 1,\n",
       " 'lgkem4wxo7': 1,\n",
       " 'tempao': 1,\n",
       " 'kassia_kr': 1,\n",
       " 'desisti': 1,\n",
       " 'qq': 1,\n",
       " 'd√≥': 1,\n",
       " 'samsung': 1,\n",
       " 'turminha': 1,\n",
       " 'merecia': 1,\n",
       " 'carteirinha': 1,\n",
       " 'itoncrf_': 1,\n",
       " 'ita√∫': 1,\n",
       " '+': 1,\n",
       " 'ilfroes': 1,\n",
       " 'bloqueando': 1,\n",
       " 'sem': 1,\n",
       " 'breve': 1,\n",
       " 'central': 1,\n",
       " 'vazou': 1,\n",
       " 'recebi': 1,\n",
       " 'tt': 1,\n",
       " 'pediu': 1,\n",
       " 'aguardo': 1,\n",
       " 'kkkkkkkkkkkkkkk': 1,\n",
       " 'plano': 1,\n",
       " 'uber': 1,\n",
       " 'clonagem': 1,\n",
       " 'reclamar': 1,\n",
       " 'ando': 1,\n",
       " 'por√©m': 1,\n",
       " 'sofisadireto': 1,\n",
       " 'acredito': 1,\n",
       " 'eternidade': 1,\n",
       " 'aprende': 1,\n",
       " 'louco': 1,\n",
       " '500': 1,\n",
       " 'migro': 1,\n",
       " 'pais': 1,\n",
       " 'deixa': 1,\n",
       " 'quebradas': 1,\n",
       " 'chat': 1,\n",
       " 'fudida': 1,\n",
       " 'respondem': 1,\n",
       " 'conte': 1,\n",
       " 'co√ßando': 1,\n",
       " 'v√°cuo': 1,\n",
       " 'sabe': 1,\n",
       " '1¬∫': 1,\n",
       " 'nas': 1,\n",
       " 'cansei': 1,\n",
       " 'nessa': 1,\n",
       " 'digital': 1,\n",
       " 'tornam': 1,\n",
       " 'indiquei': 1,\n",
       " 'aceite': 1,\n",
       " 'desgra√ßa': 1,\n",
       " 'generalizada': 1,\n",
       " 'd√°': 1,\n",
       " 'olhada': 1,\n",
       " 'papel': 1,\n",
       " 'sua': 1,\n",
       " 'adesiva': 1,\n",
       " 'milh√µes': 1,\n",
       " 'dificuldades': 1,\n",
       " 'm√£o': 1,\n",
       " 'top': 1,\n",
       " 'chamar': 1,\n",
       " 'resolvi': 1,\n",
       " 'azgxuchgp3': 1,\n",
       " 'inventou': 1,\n",
       " 'carteiro': 1,\n",
       " 'awarenesswoman': 1,\n",
       " 'serem': 1,\n",
       " '1h': 1,\n",
       " 'motivo': 1,\n",
       " 'emerg√™ncias': 1,\n",
       " 'daniele': 1,\n",
       " 'assi': 1,\n",
       " 'gj2uj2obpj': 1,\n",
       " 'boa': 1,\n",
       " 'agressivas': 1,\n",
       " 'ht‚Ä¶': 1,\n",
       " 'servem': 1,\n",
       " 'deixou': 1,\n",
       " 'abandonar': 1,\n",
       " 'surpreenderam': 1,\n",
       " 'viado': 1,\n",
       " 'ativar': 1,\n",
       " 'ganhei': 1,\n",
       " 'reservada': 1,\n",
       " 'valores': 1,\n",
       " 'minutos': 1,\n",
       " 'realizar': 1,\n",
       " 'continuar': 1,\n",
       " 'banc√°ria': 1,\n",
       " 'chamada': 1}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_counts_relevante=(lista_nubank_relev[0].value_counts()).to_dict()\n",
    "dicionario_counts_relevancia = (mensagens.Relev√¢ncia.value_counts()).to_dict()\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "def probabilidade_do_naive(lista_counts_relevante, dicionario_counts_relevancia):\n",
    "\n",
    "    verossimilhan√ßa =\n",
    "    \n",
    "    for rel, v in dicionario_counts_relevancia.items():\n",
    "        if rel == \"Relevante\"\n",
    "            total_rel = v\n",
    "    priori = total_rel/len(dicionario_counts_relevancia)\n",
    "    \n",
    "    \n",
    "    return verossimilhan√ßa*priori\n",
    "'''\n",
    "\n",
    "lista_counts_relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza an√°lise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
