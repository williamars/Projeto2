{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nome**: Jonas da Silva Lopes\n",
    "\n",
    "**Nome**: William Silva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Classificador autom√°tico de sentimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install tweepy\n",
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import emoji\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "import re \n",
    "import functools\n",
    "import operator\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***@William48253649***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Identificador da conta no twitter: @William48253649\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido\n",
    "produto = 'Nubank'\n",
    "\n",
    "#Quantidade m√≠nima de mensagens capturadas\n",
    "n = 500\n",
    "#Quantidade m√≠nima de mensagens para a base de treinamento\n",
    "t = 300\n",
    "\n",
    "#Filtro de l√≠ngua\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "    msgs.append(msg.full_text.lower()) #Lower para deixar tudo min√∫sculo e facilitar a compara√ß√£o\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um poss√≠vel vi√©s\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo n√£o existe para n√£o substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])}).set()\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])}).set()\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Ap√≥s realizar a classifica√ß√£o manual das mensagens, como irrelevante (0) ou relevante (1), partimos para  a mudan√ßa desses valores para algo mais palp√°vel para a an√°lise. Com isso, fazemos a altera√ß√£o que pode ser vista abaixo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas, para realizar isso, primeiro foi necess√°rio determinar crit√©rios para a classifica√ß√£o:\n",
    "\n",
    "- Mencionar o produto;\n",
    "- A men√ß√£o ao produto deve ser acompanhada de uma opini√£o;\n",
    "- A opini√£o pode ser demonstrada na forma de indaga√ß√µes, reclama√ß√µes, pode envolver sarcasmo, elogios e sugest√µes sobre servi√ßos;\n",
    "- A opini√£o afirmada deve ser clara;\n",
    "- Emoctions tamb√©m representam opini√µes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A quantidade de cada cada um √©: \n",
      "\n",
      " Irrelevante    184\n",
      "Relevante      116\n",
      "Name: Relev√¢ncia, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "mensagens = pd.read_excel(\"Nubank.xlsx\")\n",
    "mensagens.Relev√¢ncia = mensagens.Relev√¢ncia.astype('category')\n",
    "mensagens.Relev√¢ncia.cat.categories = ('Irrelevante', 'Relevante')\n",
    "\n",
    "print(\"A quantidade de cada cada um √©: \\n\\n\", mensagens.Relev√¢ncia.value_counts())\n",
    "\n",
    "relevante = mensagens[mensagens.Relev√¢ncia==\"Relevante\"]\n",
    "irrelevante = mensagens[mensagens.Relev√¢ncia==\"Irrelevante\"]\n",
    "\n",
    "total = len(relevante) + len(irrelevante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A probabilidade de ser relevante √© 38.666666666666664 %\n",
      "A probabilidade de ser irrelevante √© 61.33333333333333 %\n"
     ]
    }
   ],
   "source": [
    "'''A Partir dos dados obtidos, nota-se que:\n",
    "        p(relevante) = 116/300\n",
    "        p(irrelevante) = 184/300\n",
    "'''\n",
    "p_relev = 116/300*100\n",
    "print(\"A probabilidade de ser relevante √©\", p_relev, \"%\")\n",
    "\n",
    "p_irrelev = 184/300*100\n",
    "print(\"A probabilidade de ser irrelevante √©\", p_irrelev, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      rindo mas preocupada pois cada dia parece que ...\n",
       "6          eu amo o nubank mesmo https://t.co/rrpb89yes9\n",
       "7      meu pai pediu um cart√£o novo pra mim pra pegar...\n",
       "8          quem inventou o nubank nem √© gente, √© um anjo\n",
       "11     @castrocastrado @nubank se quiser eu te indico...\n",
       "12     @1masterball @haunted_electra me assusta muito...\n",
       "13     preju√≠zo nubank: banco tem 12 milh√µes de clien...\n",
       "15     @marialmeida93 @thaioliv_ @nubank menina que t...\n",
       "19     @nubank @itoncrf_ e assim mesmo n me aprovaram...\n",
       "21          depois de anos tentando,fui aceita no nubank\n",
       "22     rt @afropreticinha: aff coma assim o cart√£o da...\n",
       "25     fiquei assustada quando vi que minha fatura do...\n",
       "26     nubank nunca me liberou cr√©dito, agr q libera....\n",
       "27               meu nubank chegouüòç vos declaro fal√™ncia\n",
       "28     @lucasafoliveira @nubank ele trava assim e n√£o...\n",
       "31     s√©rio, se eu perder minha bolsa por conta do n...\n",
       "32        eu toda com meu nubank https://t.co/4av08gusbn\n",
       "33     querido @nubank, a gente queria tanto testar e...\n",
       "34     eu amo o @nubank de verdade, de cora√ß√£o, mas n...\n",
       "36     esperando o @nubank lan√ßar seu plano de previd...\n",
       "42     felizmente a nubank me aceitou esse momento √© ...\n",
       "44                         feliz q a nubank me aceitouuu\n",
       "45     maior defeito da nubank √© a facilidade p clona...\n",
       "46     eu n√£o tenho cart√£o nubank, mas eu amo essa ca...\n",
       "48     o @nubank n√£o libera a op√ß√£o de credito pro me...\n",
       "56     @robzgf quer mimo maior que um cart√£o livre de...\n",
       "57     @nubank @awarenesswoman @mabzinhaa a√≠ nubankin...\n",
       "59     eu: nossa vou ser mais reservada sabe n vou fa...\n",
       "60     estou muito orgulhoso da equipe de vendas. mes...\n",
       "63     eu ia ficar um nojo se o nubank autorizasse pa...\n",
       "                             ...                        \n",
       "231      @maluulana @nubank e eu ainda na eterna espera.\n",
       "233    pq q eu fui a √∫nica pessoa do mundo q n√£o ganh...\n",
       "234    @pianoetlux bah nem, nubank me odeia, eles me ...\n",
       "236    a central de atendimento da nubank √© me trata ...\n",
       "239    eu t√¥ assi\\npena que j√° vai tudo s√≥ hoje \\nnub...\n",
       "241    @1masterball eu tinha medo de fazer um nubank,...\n",
       "244    nubank ta cheio desses problema ai, tenho √© me...\n",
       "247    @valeriaales @nandoida @helogb__ @nubank @nuba...\n",
       "248    gente, j√° imaginou q louco se d√° um problema c...\n",
       "250                  estou ansiosa pro meu nubank chegar\n",
       "252    seria tao lindo se a @nubank deixasse eu fazer...\n",
       "254                           meu cart√£o nubank chegou ü§ó\n",
       "255    @dgianygarcia deus que me livre, esse nubank q...\n",
       "259    @nubank ai voc√™s s√£o queridos demais ‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è ob...\n",
       "260    isso tem acontecido demais com o nubank, pelo ...\n",
       "261                           @nubank conte cmg pra tudo\n",
       "264    euzinha. inclusive, @nubank aumenta meu limite...\n",
       "265    bixo o atendimento do @nubank √© sensacional, c...\n",
       "268                         nubank √© o melhor banco, pqp\n",
       "274    next e nubank duas bombas, essas porras n√£o li...\n",
       "279    @lanaalmeidaofc @nubank nunca decepciona, o me...\n",
       "280    @__chicao__ @nubank o meu a \"sorte\" √© que foi ...\n",
       "283    eu perguntei de um amigo se ele queria que eu ...\n",
       "287    n√£o aguento mais o @nubank  me lembrando de pa...\n",
       "289    aconteceu o mesmo comigo, compraram enxoval de...\n",
       "290    @nubank corre aqui por favor, to perdida. o ch...\n",
       "292    @__chicao__ @gtcarvalh0 @nubank passei por iss...\n",
       "296    to desde o dia 1¬∫ tentando pagar a porra da mi...\n",
       "298    @nubank @yasuqh kakakakakakkak pqp eu quero se...\n",
       "299    @1masterball @renatojg nossa! clonaram um nuba...\n",
       "Name: Treinamento, Length: 116, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Fun√ß√£o que troca pontua√ß√£o por espa√ßo '''\n",
    "def cleanup(text):\n",
    "    punctuation = '[!\\-.:?;/,|@\"\\'()]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    # Abaixo, determina que se troca por espa√ßo\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    \n",
    "    emoji_dividir = emoji.get_emoji_regexp().split(text_subbed)\n",
    "    espaco_dividir = [substr.split() for substr in emoji_dividir]\n",
    "    split = functools.reduce(operator.concat, espaco_dividir)\n",
    "    \n",
    "    return split\n",
    "\n",
    "# Usando a fun√ß√£o apply para fazer a limpeza nas mensagens\n",
    "nubank_relev = relevante.Treinamento.apply(cleanup)\n",
    "nubank_irrelev = irrelevante.Treinamento.apply(cleanup)\n",
    "\n",
    "# Pegando as palavras da lista de Relevantes para contar\n",
    "def pega_text(texto):\n",
    "    # Pega as palavras para colocar numa lista\n",
    "    lista = []\n",
    "    i = 0\n",
    "    for linha in texto:\n",
    "        if len(linha) > 1:\n",
    "            while i < len(linha):\n",
    "                lista.append(linha[i])\n",
    "                i += 1  \n",
    "            i = 0\n",
    "        elif len(linha) != 1 and (len(linha)-1) != 1:\n",
    "            a = texto\n",
    "            return a \n",
    "    return lista\n",
    "\n",
    "relevante.Treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequ√™ncia Absoluta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nubank           122\n",
       "o                 58\n",
       "de                54\n",
       "e                 52\n",
       "eu                47\n",
       "que               45\n",
       "a                 35\n",
       "meu               34\n",
       "me                29\n",
       "co                28\n",
       "https             28\n",
       "t                 28\n",
       "um                27\n",
       "n√£o               26\n",
       "√©                 25\n",
       "cart√£o            23\n",
       "do                23\n",
       "no                20\n",
       "uma               16\n",
       "q                 15\n",
       "pra               15\n",
       "na                15\n",
       "com               14\n",
       "to                14\n",
       "s√≥                13\n",
       "limite            12\n",
       "mais              12\n",
       "nunca             11\n",
       "tem               11\n",
       "da                11\n",
       "                ... \n",
       "deveria            1\n",
       "pariu              1\n",
       "cfo                1\n",
       "valeriaales        1\n",
       "melhores           1\n",
       "eternidade         1\n",
       "piso               1\n",
       "mo√ßo               1\n",
       "coisas             1\n",
       "surpreenderam      1\n",
       "392                1\n",
       "desisto            1\n",
       "seria              1\n",
       "aguardando         1\n",
       "500                1\n",
       "blindadah          1\n",
       "sites              1\n",
       "ganhei             1\n",
       "wan2gatnav         1\n",
       "per√≠odo            1\n",
       "marialmeida93      1\n",
       "gj2uj2obpj         1\n",
       "indevidas          1\n",
       "milh√µes            1\n",
       "yasuqh             1\n",
       "perder             1\n",
       "momento            1\n",
       "#nubank            1\n",
       "vos                1\n",
       "maioridade         1\n",
       "Name: 0, Length: 833, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Frequ√™ncia dos Relevantes\n",
    "lista_nubank_relev = pd.DataFrame(pega_text(nubank_relev))\n",
    "lista_nubank_relev[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Irrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nubank           154\n",
       "o                 71\n",
       "de                67\n",
       "e                 62\n",
       "que               60\n",
       "https             58\n",
       "co                58\n",
       "t                 58\n",
       "a                 57\n",
       "n√£o               52\n",
       "√©                 38\n",
       "um                36\n",
       "eu                34\n",
       "com               33\n",
       "da                33\n",
       "do                31\n",
       "se                30\n",
       "gente             29\n",
       "rt                28\n",
       "tem               28\n",
       "pra               26\n",
       "meu               26\n",
       "em                25\n",
       "no                25\n",
       "na                24\n",
       "voc√™              24\n",
       "cart√£o            24\n",
       "conta             22\n",
       "uma               22\n",
       "s√≥                22\n",
       "                ... \n",
       "moz√£o              1\n",
       "aumentou           1\n",
       "garantido          1\n",
       "virtual‚Äù           1\n",
       "msm                1\n",
       "xaf1um2cqj         1\n",
       "p94dsdayhw         1\n",
       "sistema            1\n",
       "lot√©ricas          1\n",
       "fa√ßa               1\n",
       "eoleite            1\n",
       "‚úåüèΩ                 1\n",
       "bora               1\n",
       "conseguindo        1\n",
       "vejo               1\n",
       "bebada             1\n",
       "piscina            1\n",
       "gyroq3y6is         1\n",
       "esquecer           1\n",
       "kinnybouvier_      1\n",
       "rindo              1\n",
       "uhul               1\n",
       "e7oybscozu         1\n",
       "mlk                1\n",
       "vagas              1\n",
       "receber            1\n",
       "outra              1\n",
       "#nubank            1\n",
       "alguma             1\n",
       "fg9sugv9mc         1\n",
       "Name: 0, Length: 1114, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Frequ√™ncia dos Irrelevantes\n",
    "lista_nubank_irrelev = pd.DataFrame(pega_text(nubank_irrelev))\n",
    "lista_nubank_irrelev[0].value_counts()\n",
    "lista_nubank_irrelev[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequ√™ncia Relativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nubank           0.056092\n",
       "o                0.026667\n",
       "de               0.024828\n",
       "e                0.023908\n",
       "eu               0.021609\n",
       "que              0.020690\n",
       "a                0.016092\n",
       "meu              0.015632\n",
       "me               0.013333\n",
       "co               0.012874\n",
       "https            0.012874\n",
       "t                0.012874\n",
       "um               0.012414\n",
       "n√£o              0.011954\n",
       "√©                0.011494\n",
       "cart√£o           0.010575\n",
       "do               0.010575\n",
       "no               0.009195\n",
       "uma              0.007356\n",
       "q                0.006897\n",
       "pra              0.006897\n",
       "na               0.006897\n",
       "com              0.006437\n",
       "to               0.006437\n",
       "s√≥               0.005977\n",
       "limite           0.005517\n",
       "mais             0.005517\n",
       "nunca            0.005057\n",
       "tem              0.005057\n",
       "da               0.005057\n",
       "                   ...   \n",
       "deveria          0.000460\n",
       "pariu            0.000460\n",
       "cfo              0.000460\n",
       "valeriaales      0.000460\n",
       "melhores         0.000460\n",
       "eternidade       0.000460\n",
       "piso             0.000460\n",
       "mo√ßo             0.000460\n",
       "coisas           0.000460\n",
       "surpreenderam    0.000460\n",
       "392              0.000460\n",
       "desisto          0.000460\n",
       "seria            0.000460\n",
       "aguardando       0.000460\n",
       "500              0.000460\n",
       "blindadah        0.000460\n",
       "sites            0.000460\n",
       "ganhei           0.000460\n",
       "wan2gatnav       0.000460\n",
       "per√≠odo          0.000460\n",
       "marialmeida93    0.000460\n",
       "gj2uj2obpj       0.000460\n",
       "indevidas        0.000460\n",
       "milh√µes          0.000460\n",
       "yasuqh           0.000460\n",
       "perder           0.000460\n",
       "momento          0.000460\n",
       "#nubank          0.000460\n",
       "vos              0.000460\n",
       "maioridade       0.000460\n",
       "Name: 0, Length: 833, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_nubank_relev[0].value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Irrelevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nubank           0.045441\n",
       "o                0.020950\n",
       "de               0.019770\n",
       "e                0.018294\n",
       "que              0.017704\n",
       "https            0.017114\n",
       "co               0.017114\n",
       "t                0.017114\n",
       "a                0.016819\n",
       "n√£o              0.015344\n",
       "√©                0.011213\n",
       "um               0.010623\n",
       "eu               0.010032\n",
       "com              0.009737\n",
       "da               0.009737\n",
       "do               0.009147\n",
       "se               0.008852\n",
       "gente            0.008557\n",
       "rt               0.008262\n",
       "tem              0.008262\n",
       "pra              0.007672\n",
       "meu              0.007672\n",
       "em               0.007377\n",
       "no               0.007377\n",
       "na               0.007082\n",
       "voc√™             0.007082\n",
       "cart√£o           0.007082\n",
       "conta            0.006492\n",
       "uma              0.006492\n",
       "s√≥               0.006492\n",
       "                   ...   \n",
       "moz√£o            0.000295\n",
       "aumentou         0.000295\n",
       "garantido        0.000295\n",
       "virtual‚Äù         0.000295\n",
       "msm              0.000295\n",
       "xaf1um2cqj       0.000295\n",
       "p94dsdayhw       0.000295\n",
       "sistema          0.000295\n",
       "lot√©ricas        0.000295\n",
       "fa√ßa             0.000295\n",
       "eoleite          0.000295\n",
       "‚úåüèΩ               0.000295\n",
       "bora             0.000295\n",
       "conseguindo      0.000295\n",
       "vejo             0.000295\n",
       "bebada           0.000295\n",
       "piscina          0.000295\n",
       "gyroq3y6is       0.000295\n",
       "esquecer         0.000295\n",
       "kinnybouvier_    0.000295\n",
       "rindo            0.000295\n",
       "uhul             0.000295\n",
       "e7oybscozu       0.000295\n",
       "mlk              0.000295\n",
       "vagas            0.000295\n",
       "receber          0.000295\n",
       "outra            0.000295\n",
       "#nubank          0.000295\n",
       "alguma           0.000295\n",
       "fg9sugv9mc       0.000295\n",
       "Name: 0, Length: 1114, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_nubank_irrelev[0].value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, estamos ensinando nosso treinador a identificar as probabilidades, para posteriormente fazer a identifica√ß√£o e a leitura. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Irrelevante': 184, 'Relevante': 116}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Fazendo dicion√°rios, para serem utilizados com objetivos na fun√ß√£o'''\n",
    "\n",
    "# Dicion√°rio que guarda, dos relevantes, as palavras e quantas vezes apareceu\n",
    "lista_counts_relevante = (lista_nubank_relev[0].value_counts()).to_dict()\n",
    "\n",
    "# Dicion√°rio que guarda a quantidade de relevantes e irrelevantes\n",
    "dicionario_counts_relevancia = (mensagens.Relev√¢ncia.value_counts()).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.253478727369117e-19\n"
     ]
    }
   ],
   "source": [
    "# Fun√ß√£o que calcula as probabilidade de ser relevante\n",
    "def probabilidade_do_naive(mensagens, lista_counts_relevante, dicionario_counts_relevancia, total, linhas_mens):\n",
    "    verossimilhan√ßa = 1\n",
    "    for word in linhas_mens:\n",
    "        for key, values in lista_counts_relevante.items():\n",
    "            if key == word:\n",
    "                verossimilhan√ßa *= (values+1)/len(lista_nubank_relev)\n",
    "    \n",
    "    for rel, v in dicionario_counts_relevancia.items():\n",
    "        if rel == \"Relevante\":\n",
    "            total_rel = v\n",
    "    priori = total_rel/total\n",
    "    \n",
    "    return verossimilhan√ßa * priori\n",
    "\n",
    "print(probabilidade_do_naive(mensagens, lista_counts_relevante, dicionario_counts_relevancia, total, linhas_mens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "probs_relevante = [0]*300\n",
    "\n",
    "i = 0\n",
    "for h in probs_relevante:\n",
    "    linhas_mens = mensagens.Treinamento.apply(cleanup)[i]\n",
    "    probs_relevante[i] = probabilidade_do_naive(mensagens, lista_counts_relevante, dicionario_counts_relevancia, total, linhas_mens)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Irrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicion√°rio que guarda, dos irrelevantes, as palavras e quantas vezes apareceu\n",
    "lista_counts_irrelevante = (lista_nubank_irrelev[0].value_counts()).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o que calcula as probabilidade de ser irrelevante\n",
    "def probabilidade_do_naive_irr(mensagens, lista_counts_irrelevante, dicionario_counts_relevancia, total, linhas_mens):\n",
    "    verossimilhan√ßa = 1\n",
    "    # Identificando a quantidade e calculando a probabilidade de cada palavra do tweet\n",
    "    for word in linhas_mens:\n",
    "        for key, values in lista_counts_irrelevante.items():\n",
    "            if key == word:\n",
    "                verossimilhan√ßa *= (values+1) / len(lista_nubank_irrelev)\n",
    "    \n",
    "    # Pegando a probabilidade e dividindo pelo total, usando Naive Bayes\n",
    "    for rel, v in dicionario_counts_relevancia.items():\n",
    "        if rel == \"Irrelevante\":\n",
    "            total_rel = v\n",
    "    priori = total_rel/total\n",
    "    \n",
    "    return verossimilhan√ßa * priori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_irrelevante = [0]*300\n",
    "\n",
    "i = 0\n",
    "for h in probs_irrelevante:\n",
    "    linhas_mens = mensagens.Treinamento.apply(cleanup)[i]\n",
    "    probs_irrelevante[i] = probabilidade_do_naive_irr(mensagens, lista_counts_irrelevante, dicionario_counts_relevancia, total, linhas_mens)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza an√°lise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
