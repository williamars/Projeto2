{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - CiÃªncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nome**: Jonas da Silva Lopes\n",
    "\n",
    "**Nome**: William Silva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Classificador automÃ¡tico de sentimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install tweepy\n",
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import emoji\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "import re \n",
    "import functools\n",
    "import operator\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***@William48253649***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Identificador da conta no twitter: @William48253649\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido\n",
    "produto = 'Nubank'\n",
    "\n",
    "#Quantidade mÃ­nima de mensagens capturadas\n",
    "n = 500\n",
    "#Quantidade mÃ­nima de mensagens para a base de treinamento\n",
    "t = 300\n",
    "\n",
    "#Filtro de lÃ­ngua\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "    msgs.append(msg.full_text.lower()) #Lower para deixar tudo minÃºsculo e facilitar a comparaÃ§Ã£o\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um possÃ­vel viÃ©s\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo nÃ£o existe para nÃ£o substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])}).set()\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])}).set()\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "ApÃ³s realizar a classificaÃ§Ã£o manual das mensagens, como irrelevante (0) ou relevante (1), partimos para  a mudanÃ§a desses valores para algo mais palpÃ¡vel para a anÃ¡lise. Com isso, fazemos a alteraÃ§Ã£o que pode ser vista abaixo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas, para realizar isso, primeiro foi necessÃ¡rio determinar critÃ©rios para a classificaÃ§Ã£o:\n",
    "\n",
    "- Mencionar o produto;\n",
    "- A menÃ§Ã£o ao produto deve ser acompanhada de uma opiniÃ£o;\n",
    "- A opiniÃ£o pode ser demonstrada na forma de indagaÃ§Ãµes, reclamaÃ§Ãµes, pode envolver sarcasmo, elogios e sugestÃµes sobre serviÃ§os;\n",
    "- A opiniÃ£o afirmada deve ser clara;\n",
    "- Emoctions tambÃ©m representam opiniÃµes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A quantidade de cada cada um Ã©: \n",
      "\n",
      " Irrelevante    184\n",
      "Relevante      116\n",
      "Name: RelevÃ¢ncia, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "mensagens = pd.read_excel(\"Nubank.xlsx\")\n",
    "mensagens.RelevÃ¢ncia = mensagens.RelevÃ¢ncia.astype('category')\n",
    "mensagens.RelevÃ¢ncia.cat.categories = ('Irrelevante', 'Relevante')\n",
    "\n",
    "print(\"A quantidade de cada cada um Ã©: \\n\\n\", mensagens.RelevÃ¢ncia.value_counts())\n",
    "\n",
    "relevante = mensagens[mensagens.RelevÃ¢ncia==\"Relevante\"]\n",
    "irrelevante = mensagens[mensagens.RelevÃ¢ncia==\"Irrelevante\"]\n",
    "\n",
    "total = len(relevante) + len(irrelevante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A probabilidade de ser relevante Ã© 38.666666666666664 %\n",
      "A probabilidade de ser irrelevante Ã© 61.33333333333333 %\n"
     ]
    }
   ],
   "source": [
    "'''A Partir dos dados obtidos, nota-se que:\n",
    "        p(relevante) = 116/300\n",
    "        p(irrelevante) = 184/300\n",
    "'''\n",
    "p_relev = 116/300*100\n",
    "print(\"A probabilidade de ser relevante Ã©\", p_relev, \"%\")\n",
    "\n",
    "p_irrelev = 184/300*100\n",
    "print(\"A probabilidade de ser irrelevante Ã©\", p_irrelev, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      rindo mas preocupada pois cada dia parece que ...\n",
       "6          eu amo o nubank mesmo https://t.co/rrpb89yes9\n",
       "7      meu pai pediu um cartÃ£o novo pra mim pra pegar...\n",
       "8          quem inventou o nubank nem Ã© gente, Ã© um anjo\n",
       "11     @castrocastrado @nubank se quiser eu te indico...\n",
       "12     @1masterball @haunted_electra me assusta muito...\n",
       "13     prejuÃ­zo nubank: banco tem 12 milhÃµes de clien...\n",
       "15     @marialmeida93 @thaioliv_ @nubank menina que t...\n",
       "19     @nubank @itoncrf_ e assim mesmo n me aprovaram...\n",
       "21          depois de anos tentando,fui aceita no nubank\n",
       "22     rt @afropreticinha: aff coma assim o cartÃ£o da...\n",
       "25     fiquei assustada quando vi que minha fatura do...\n",
       "26     nubank nunca me liberou crÃ©dito, agr q libera....\n",
       "27               meu nubank chegouðŸ˜ vos declaro falÃªncia\n",
       "28     @lucasafoliveira @nubank ele trava assim e nÃ£o...\n",
       "31     sÃ©rio, se eu perder minha bolsa por conta do n...\n",
       "32        eu toda com meu nubank https://t.co/4av08gusbn\n",
       "33     querido @nubank, a gente queria tanto testar e...\n",
       "34     eu amo o @nubank de verdade, de coraÃ§Ã£o, mas n...\n",
       "36     esperando o @nubank lanÃ§ar seu plano de previd...\n",
       "42     felizmente a nubank me aceitou esse momento Ã© ...\n",
       "44                         feliz q a nubank me aceitouuu\n",
       "45     maior defeito da nubank Ã© a facilidade p clona...\n",
       "46     eu nÃ£o tenho cartÃ£o nubank, mas eu amo essa ca...\n",
       "48     o @nubank nÃ£o libera a opÃ§Ã£o de credito pro me...\n",
       "56     @robzgf quer mimo maior que um cartÃ£o livre de...\n",
       "57     @nubank @awarenesswoman @mabzinhaa aÃ­ nubankin...\n",
       "59     eu: nossa vou ser mais reservada sabe n vou fa...\n",
       "60     estou muito orgulhoso da equipe de vendas. mes...\n",
       "63     eu ia ficar um nojo se o nubank autorizasse pa...\n",
       "                             ...                        \n",
       "231      @maluulana @nubank e eu ainda na eterna espera.\n",
       "233    pq q eu fui a Ãºnica pessoa do mundo q nÃ£o ganh...\n",
       "234    @pianoetlux bah nem, nubank me odeia, eles me ...\n",
       "236    a central de atendimento da nubank Ã© me trata ...\n",
       "239    eu tÃ´ assi\\npena que jÃ¡ vai tudo sÃ³ hoje \\nnub...\n",
       "241    @1masterball eu tinha medo de fazer um nubank,...\n",
       "244    nubank ta cheio desses problema ai, tenho Ã© me...\n",
       "247    @valeriaales @nandoida @helogb__ @nubank @nuba...\n",
       "248    gente, jÃ¡ imaginou q louco se dÃ¡ um problema c...\n",
       "250                  estou ansiosa pro meu nubank chegar\n",
       "252    seria tao lindo se a @nubank deixasse eu fazer...\n",
       "254                           meu cartÃ£o nubank chegou ðŸ¤—\n",
       "255    @dgianygarcia deus que me livre, esse nubank q...\n",
       "259    @nubank ai vocÃªs sÃ£o queridos demais â¤ï¸â¤ï¸â¤ï¸ ob...\n",
       "260    isso tem acontecido demais com o nubank, pelo ...\n",
       "261                           @nubank conte cmg pra tudo\n",
       "264    euzinha. inclusive, @nubank aumenta meu limite...\n",
       "265    bixo o atendimento do @nubank Ã© sensacional, c...\n",
       "268                         nubank Ã© o melhor banco, pqp\n",
       "274    next e nubank duas bombas, essas porras nÃ£o li...\n",
       "279    @lanaalmeidaofc @nubank nunca decepciona, o me...\n",
       "280    @__chicao__ @nubank o meu a \"sorte\" Ã© que foi ...\n",
       "283    eu perguntei de um amigo se ele queria que eu ...\n",
       "287    nÃ£o aguento mais o @nubank  me lembrando de pa...\n",
       "289    aconteceu o mesmo comigo, compraram enxoval de...\n",
       "290    @nubank corre aqui por favor, to perdida. o ch...\n",
       "292    @__chicao__ @gtcarvalh0 @nubank passei por iss...\n",
       "296    to desde o dia 1Âº tentando pagar a porra da mi...\n",
       "298    @nubank @yasuqh kakakakakakkak pqp eu quero se...\n",
       "299    @1masterball @renatojg nossa! clonaram um nuba...\n",
       "Name: Treinamento, Length: 116, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' FunÃ§Ã£o que troca pontuaÃ§Ã£o por espaÃ§o '''\n",
    "def cleanup(text):\n",
    "    punctuation = '[!\\-.:?;/,|@\"\\'()]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    # Abaixo, determina que se troca por espaÃ§o\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    \n",
    "    emoji_dividir = emoji.get_emoji_regexp().split(text_subbed)\n",
    "    espaco_dividir = [substr.split() for substr in emoji_dividir]\n",
    "    split = functools.reduce(operator.concat, espaco_dividir)\n",
    "    \n",
    "    return split\n",
    "\n",
    "# Usando a funÃ§Ã£o apply para fazer a limpeza nas mensagens\n",
    "nubank_relev = relevante.Treinamento.apply(cleanup)\n",
    "nubank_irrelev = irrelevante.Treinamento.apply(cleanup)\n",
    "\n",
    "# Pegando as palavras da lista de Relevantes para contar\n",
    "def pega_text(texto):\n",
    "    # Pega as palavras para colocar numa lista\n",
    "    lista = []\n",
    "    i = 0\n",
    "    for linha in texto:\n",
    "        if len(linha) > 1:\n",
    "            while i < len(linha):\n",
    "                lista.append(linha[i])\n",
    "                i += 1  \n",
    "            i = 0\n",
    "        elif len(linha) != 1 and (len(linha)-1) != 1:\n",
    "            a = texto\n",
    "            return a \n",
    "    return lista\n",
    "\n",
    "relevante.Treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FrequÃªncia Absoluta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nubank           122\n",
       "o                 58\n",
       "de                54\n",
       "e                 52\n",
       "eu                47\n",
       "que               45\n",
       "a                 35\n",
       "meu               34\n",
       "me                29\n",
       "co                28\n",
       "https             28\n",
       "t                 28\n",
       "um                27\n",
       "nÃ£o               26\n",
       "Ã©                 25\n",
       "cartÃ£o            23\n",
       "do                23\n",
       "no                20\n",
       "uma               16\n",
       "q                 15\n",
       "pra               15\n",
       "na                15\n",
       "com               14\n",
       "to                14\n",
       "sÃ³                13\n",
       "limite            12\n",
       "mais              12\n",
       "nunca             11\n",
       "tem               11\n",
       "da                11\n",
       "                ... \n",
       "deveria            1\n",
       "pariu              1\n",
       "cfo                1\n",
       "valeriaales        1\n",
       "melhores           1\n",
       "eternidade         1\n",
       "piso               1\n",
       "moÃ§o               1\n",
       "coisas             1\n",
       "surpreenderam      1\n",
       "392                1\n",
       "desisto            1\n",
       "seria              1\n",
       "aguardando         1\n",
       "500                1\n",
       "blindadah          1\n",
       "sites              1\n",
       "ganhei             1\n",
       "wan2gatnav         1\n",
       "perÃ­odo            1\n",
       "marialmeida93      1\n",
       "gj2uj2obpj         1\n",
       "indevidas          1\n",
       "milhÃµes            1\n",
       "yasuqh             1\n",
       "perder             1\n",
       "momento            1\n",
       "#nubank            1\n",
       "vos                1\n",
       "maioridade         1\n",
       "Name: 0, Length: 833, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FrequÃªncia dos Relevantes\n",
    "lista_nubank_relev = pd.DataFrame(pega_text(nubank_relev))\n",
    "lista_nubank_relev[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Irrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nubank           154\n",
       "o                 71\n",
       "de                67\n",
       "e                 62\n",
       "que               60\n",
       "https             58\n",
       "co                58\n",
       "t                 58\n",
       "a                 57\n",
       "nÃ£o               52\n",
       "Ã©                 38\n",
       "um                36\n",
       "eu                34\n",
       "com               33\n",
       "da                33\n",
       "do                31\n",
       "se                30\n",
       "gente             29\n",
       "rt                28\n",
       "tem               28\n",
       "pra               26\n",
       "meu               26\n",
       "em                25\n",
       "no                25\n",
       "na                24\n",
       "vocÃª              24\n",
       "cartÃ£o            24\n",
       "conta             22\n",
       "uma               22\n",
       "sÃ³                22\n",
       "                ... \n",
       "mozÃ£o              1\n",
       "aumentou           1\n",
       "garantido          1\n",
       "virtualâ€           1\n",
       "msm                1\n",
       "xaf1um2cqj         1\n",
       "p94dsdayhw         1\n",
       "sistema            1\n",
       "lotÃ©ricas          1\n",
       "faÃ§a               1\n",
       "eoleite            1\n",
       "âœŒðŸ½                 1\n",
       "bora               1\n",
       "conseguindo        1\n",
       "vejo               1\n",
       "bebada             1\n",
       "piscina            1\n",
       "gyroq3y6is         1\n",
       "esquecer           1\n",
       "kinnybouvier_      1\n",
       "rindo              1\n",
       "uhul               1\n",
       "e7oybscozu         1\n",
       "mlk                1\n",
       "vagas              1\n",
       "receber            1\n",
       "outra              1\n",
       "#nubank            1\n",
       "alguma             1\n",
       "fg9sugv9mc         1\n",
       "Name: 0, Length: 1114, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FrequÃªncia dos Irrelevantes\n",
    "lista_nubank_irrelev = pd.DataFrame(pega_text(nubank_irrelev))\n",
    "lista_nubank_irrelev[0].value_counts()\n",
    "lista_nubank_irrelev[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FrequÃªncia Relativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nubank           0.056092\n",
       "o                0.026667\n",
       "de               0.024828\n",
       "e                0.023908\n",
       "eu               0.021609\n",
       "que              0.020690\n",
       "a                0.016092\n",
       "meu              0.015632\n",
       "me               0.013333\n",
       "co               0.012874\n",
       "https            0.012874\n",
       "t                0.012874\n",
       "um               0.012414\n",
       "nÃ£o              0.011954\n",
       "Ã©                0.011494\n",
       "cartÃ£o           0.010575\n",
       "do               0.010575\n",
       "no               0.009195\n",
       "uma              0.007356\n",
       "q                0.006897\n",
       "pra              0.006897\n",
       "na               0.006897\n",
       "com              0.006437\n",
       "to               0.006437\n",
       "sÃ³               0.005977\n",
       "limite           0.005517\n",
       "mais             0.005517\n",
       "nunca            0.005057\n",
       "tem              0.005057\n",
       "da               0.005057\n",
       "                   ...   \n",
       "deveria          0.000460\n",
       "pariu            0.000460\n",
       "cfo              0.000460\n",
       "valeriaales      0.000460\n",
       "melhores         0.000460\n",
       "eternidade       0.000460\n",
       "piso             0.000460\n",
       "moÃ§o             0.000460\n",
       "coisas           0.000460\n",
       "surpreenderam    0.000460\n",
       "392              0.000460\n",
       "desisto          0.000460\n",
       "seria            0.000460\n",
       "aguardando       0.000460\n",
       "500              0.000460\n",
       "blindadah        0.000460\n",
       "sites            0.000460\n",
       "ganhei           0.000460\n",
       "wan2gatnav       0.000460\n",
       "perÃ­odo          0.000460\n",
       "marialmeida93    0.000460\n",
       "gj2uj2obpj       0.000460\n",
       "indevidas        0.000460\n",
       "milhÃµes          0.000460\n",
       "yasuqh           0.000460\n",
       "perder           0.000460\n",
       "momento          0.000460\n",
       "#nubank          0.000460\n",
       "vos              0.000460\n",
       "maioridade       0.000460\n",
       "Name: 0, Length: 833, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_nubank_relev[0].value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Irrelevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nubank           0.045441\n",
       "o                0.020950\n",
       "de               0.019770\n",
       "e                0.018294\n",
       "que              0.017704\n",
       "https            0.017114\n",
       "co               0.017114\n",
       "t                0.017114\n",
       "a                0.016819\n",
       "nÃ£o              0.015344\n",
       "Ã©                0.011213\n",
       "um               0.010623\n",
       "eu               0.010032\n",
       "com              0.009737\n",
       "da               0.009737\n",
       "do               0.009147\n",
       "se               0.008852\n",
       "gente            0.008557\n",
       "rt               0.008262\n",
       "tem              0.008262\n",
       "pra              0.007672\n",
       "meu              0.007672\n",
       "em               0.007377\n",
       "no               0.007377\n",
       "na               0.007082\n",
       "vocÃª             0.007082\n",
       "cartÃ£o           0.007082\n",
       "conta            0.006492\n",
       "uma              0.006492\n",
       "sÃ³               0.006492\n",
       "                   ...   \n",
       "mozÃ£o            0.000295\n",
       "aumentou         0.000295\n",
       "garantido        0.000295\n",
       "virtualâ€         0.000295\n",
       "msm              0.000295\n",
       "xaf1um2cqj       0.000295\n",
       "p94dsdayhw       0.000295\n",
       "sistema          0.000295\n",
       "lotÃ©ricas        0.000295\n",
       "faÃ§a             0.000295\n",
       "eoleite          0.000295\n",
       "âœŒðŸ½               0.000295\n",
       "bora             0.000295\n",
       "conseguindo      0.000295\n",
       "vejo             0.000295\n",
       "bebada           0.000295\n",
       "piscina          0.000295\n",
       "gyroq3y6is       0.000295\n",
       "esquecer         0.000295\n",
       "kinnybouvier_    0.000295\n",
       "rindo            0.000295\n",
       "uhul             0.000295\n",
       "e7oybscozu       0.000295\n",
       "mlk              0.000295\n",
       "vagas            0.000295\n",
       "receber          0.000295\n",
       "outra            0.000295\n",
       "#nubank          0.000295\n",
       "alguma           0.000295\n",
       "fg9sugv9mc       0.000295\n",
       "Name: 0, Length: 1114, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_nubank_irrelev[0].value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, estamos ensinando nosso treinador a identificar as probabilidades, para posteriormente fazer a identificaÃ§Ã£o e a leitura. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Irrelevante': 184, 'Relevante': 116}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Fazendo dicionÃ¡rios, para serem utilizados com objetivos na funÃ§Ã£o'''\n",
    "\n",
    "# DicionÃ¡rio que guarda, dos relevantes, as palavras e quantas vezes apareceu\n",
    "lista_counts_relevante = (lista_nubank_relev[0].value_counts()).to_dict()\n",
    "\n",
    "# DicionÃ¡rio que guarda a quantidade de relevantes e irrelevantes\n",
    "dicionario_counts_relevancia = (mensagens.RelevÃ¢ncia.value_counts()).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.253478727369117e-19\n"
     ]
    }
   ],
   "source": [
    "# FunÃ§Ã£o que calcula as probabilidade de ser relevante\n",
    "def probabilidade_do_naive(mensagens, lista_counts_relevante, dicionario_counts_relevancia, total, linhas_mens):\n",
    "    verossimilhanÃ§a = 1\n",
    "    for word in linhas_mens:\n",
    "        for key, values in lista_counts_relevante.items():\n",
    "            if key == word:\n",
    "                verossimilhanÃ§a *= (values+1)/len(lista_nubank_relev)\n",
    "    \n",
    "    for rel, v in dicionario_counts_relevancia.items():\n",
    "        if rel == \"Relevante\":\n",
    "            total_rel = v\n",
    "    priori = total_rel/total\n",
    "    \n",
    "    return verossimilhanÃ§a * priori\n",
    "\n",
    "print(probabilidade_do_naive(mensagens, lista_counts_relevante, dicionario_counts_relevancia, total, linhas_mens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "probs_relevante = [0]*300\n",
    "\n",
    "i = 0\n",
    "for h in probs_relevante:\n",
    "    linhas_mens = mensagens.Treinamento.apply(cleanup)[i]\n",
    "    probs_relevante[i] = probabilidade_do_naive(mensagens, lista_counts_relevante, dicionario_counts_relevancia, total, linhas_mens)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Irrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DicionÃ¡rio que guarda, dos irrelevantes, as palavras e quantas vezes apareceu\n",
    "lista_counts_irrelevante = (lista_nubank_irrelev[0].value_counts()).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FunÃ§Ã£o que calcula as probabilidade de ser irrelevante\n",
    "def probabilidade_do_naive_irr(mensagens, lista_counts_irrelevante, dicionario_counts_relevancia, total, linhas_mens):\n",
    "    verossimilhanÃ§a = 1\n",
    "    # Identificando a quantidade e calculando a probabilidade de cada palavra do tweet\n",
    "    for word in linhas_mens:\n",
    "        for key, values in lista_counts_irrelevante.items():\n",
    "            if key == word:\n",
    "                verossimilhanÃ§a *= (values+1) / len(lista_nubank_irrelev)\n",
    "    \n",
    "    # Pegando a probabilidade e dividindo pelo total, usando Naive Bayes\n",
    "    for rel, v in dicionario_counts_relevancia.items():\n",
    "        if rel == \"Irrelevante\":\n",
    "            total_rel = v\n",
    "    priori = total_rel/total\n",
    "    \n",
    "    return verossimilhanÃ§a * priori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_irrelevante = [0]*300\n",
    "\n",
    "i = 0\n",
    "for h in probs_irrelevante:\n",
    "    linhas_mens = mensagens.Treinamento.apply(cleanup)[i]\n",
    "    probs_irrelevante[i] = probabilidade_do_naive_irr(mensagens, lista_counts_irrelevante, dicionario_counts_relevancia, total, linhas_mens)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora vocÃª deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AperfeiÃ§oamento:\n",
    "\n",
    "Os trabalhos vÃ£o evoluir em conceito dependendo da quantidade de itens avanÃ§ados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separaÃ§Ã£o de espaÃ§os entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transformaÃ§Ãµes que nÃ£o afetem a qualidade da informaÃ§Ã£o ou classificaÃ§Ã£o\n",
    "* Criar categorias intermediÃ¡rias de relevÃ¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que nÃ£o posso usar o prÃ³prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenÃ¡rios para NaÃ¯ve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicaÃ§Ãµes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza anÃ¡lise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReferÃªncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
