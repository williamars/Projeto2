{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Faculdade: Insper - Instituto de Ensino e Pesquisa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nome**: Jonas da Silva Lopes\n",
    "\n",
    "**Nome**: William Augusto Reis da Silva\n",
    "\n",
    "**Turma**: Engenharia | 2A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Classificador automático de sentimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este projeto consiste na análise de dados de tweets, por meio da biblioteca tweepy, para realizar um classificador de sentimento, demonstrando se um tweety é relevante ou irrelevante. Para isso, realiamos algumas funções para que possamos determinar esta análise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando e instalando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install tweepy\n",
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import emoji\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "import re \n",
    "import functools\n",
    "import operator\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta utilizada: ***@William48253649***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Identificador da conta no twitter: @William48253649\n",
    "\n",
    "# Leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "# Configurando a biblioteca\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O produto escolhido para a análise será a empresa Nubank, tendo em vista que é uma empresa em alta e que possui, possivelmente, diversas opiniões no Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido\n",
    "produto = 'Nubank'\n",
    "\n",
    "#Quantidade mínima de mensagens capturadas\n",
    "n = 500\n",
    "#Quantidade mínima de mensagens para a base de treinamento\n",
    "t = 300\n",
    "\n",
    "#Filtro de língua\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "# Inicia a captura\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "    msgs.append(msg.full_text.lower()) # Lower para deixar tudo minúsculo e facilitar a comparação\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "# Embaralhando as mensagens para reduzir um possível viés\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Verifica se o arquivo não existe para não substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    # Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    # Divide o conjunto de mensagens em duas planilhas\n",
    "    # Planilha de treinamento\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])}).set()\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    # Planilha de teste\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])}).set()\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    # Fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Após realizar a classificação manual das mensagens, como irrelevante (0) ou relevante (1), partimos para  a mudança desses valores para algo mais palpável para a análise. Com isso, fazemos a alteração que pode ser vista abaixo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas, para realizar isso, primeiro foi necessário determinar critérios para a classificação:\n",
    "\n",
    "- Mencionar o produto;\n",
    "- A menção ao produto deve ser acompanhada de uma opinião;\n",
    "- A opinião pode ser demonstrada na forma de indagações, reclamações, pode envolver sarcasmo, elogios e sugestões sobre serviços;\n",
    "- A opinião afirmada deve ser clara;\n",
    "- Emoctions também representam opiniões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A quantidade de cada cada um é: \n",
      "\n",
      " Irrelevante    184\n",
      "Relevante      116\n",
      "Name: Relevância, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Lendo o arquivo Nubank\n",
    "mensagens = pd.read_excel(\"Nubank.xlsx\")\n",
    "mensagens.Relevância = mensagens.Relevância.astype('category')\n",
    "mensagens.Relevância.cat.categories = ('Irrelevante', 'Relevante')\n",
    "\n",
    "\n",
    "relevante = mensagens[mensagens.Relevância==\"Relevante\"]\n",
    "irrelevante = mensagens[mensagens.Relevância==\"Irrelevante\"]\n",
    "\n",
    "total = len(relevante) + len(irrelevante)\n",
    "\n",
    "print(\"A quantidade de cada cada um é: \\n\\n\", mensagens.Relevância.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A probabilidade de ser relevante é 38.666666666666664 %\n",
      "A probabilidade de ser irrelevante é 61.33333333333333 %\n"
     ]
    }
   ],
   "source": [
    "'''A Partir dos dados obtidos, nota-se que:\n",
    "        p(relevante) = 116/300\n",
    "        p(irrelevante) = 184/300\n",
    "'''\n",
    "p_relev = 116/300*100\n",
    "print(\"A probabilidade de ser relevante é\", p_relev, \"%\")\n",
    "\n",
    "p_irrelev = 184/300*100\n",
    "print(\"A probabilidade de ser irrelevante é\", p_irrelev, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "''' Função que troca pontuação por espaço '''\n",
    "def cleanup(text):\n",
    "    punctuation = '[!\\-.:?;/,|@\"\\'()]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    # Abaixo, determina que se troca por espaço\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    \n",
    "    emoji_dividir = emoji.get_emoji_regexp().split(text_subbed)\n",
    "    espaco_dividir = [substr.split() for substr in emoji_dividir]\n",
    "    split = functools.reduce(operator.concat, espaco_dividir)\n",
    "    \n",
    "    return split\n",
    "\n",
    "# Usando a função apply para fazer a limpeza nas mensagens\n",
    "nubank_relev = relevante.Treinamento.apply(cleanup)\n",
    "nubank_irrelev = irrelevante.Treinamento.apply(cleanup)\n",
    "\n",
    "# Pegando as palavras da lista de Relevantes para contar\n",
    "def pega_text(texto):\n",
    "    # Pega as palavras para colocar numa lista\n",
    "    lista = []\n",
    "    i = 0\n",
    "    for linha in texto:\n",
    "        if len(linha) > 1:\n",
    "            while i < len(linha):\n",
    "                lista.append(linha[i])\n",
    "                i += 1  \n",
    "            i = 0\n",
    "        elif len(linha) != 1 and (len(linha)-1) != 1:\n",
    "            a = texto\n",
    "            return a \n",
    "    return lista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequência Absoluta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nubank           122\n",
       "o                 58\n",
       "de                54\n",
       "e                 52\n",
       "eu                47\n",
       "que               45\n",
       "a                 35\n",
       "meu               34\n",
       "me                29\n",
       "co                28\n",
       "https             28\n",
       "t                 28\n",
       "um                27\n",
       "não               26\n",
       "é                 25\n",
       "cartão            23\n",
       "do                23\n",
       "no                20\n",
       "uma               16\n",
       "q                 15\n",
       "pra               15\n",
       "na                15\n",
       "com               14\n",
       "to                14\n",
       "só                13\n",
       "limite            12\n",
       "mais              12\n",
       "nunca             11\n",
       "tem               11\n",
       "da                11\n",
       "                ... \n",
       "deveria            1\n",
       "pariu              1\n",
       "cfo                1\n",
       "valeriaales        1\n",
       "melhores           1\n",
       "eternidade         1\n",
       "piso               1\n",
       "moço               1\n",
       "coisas             1\n",
       "surpreenderam      1\n",
       "392                1\n",
       "desisto            1\n",
       "seria              1\n",
       "aguardando         1\n",
       "500                1\n",
       "blindadah          1\n",
       "sites              1\n",
       "ganhei             1\n",
       "wan2gatnav         1\n",
       "período            1\n",
       "marialmeida93      1\n",
       "gj2uj2obpj         1\n",
       "indevidas          1\n",
       "milhões            1\n",
       "yasuqh             1\n",
       "perder             1\n",
       "momento            1\n",
       "#nubank            1\n",
       "vos                1\n",
       "maioridade         1\n",
       "Name: 0, Length: 833, dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Frequência dos Relevantes\n",
    "lista_nubank_relev = pd.DataFrame(pega_text(nubank_relev))\n",
    "lista_nubank_relev[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Irrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nubank           154\n",
       "o                 71\n",
       "de                67\n",
       "e                 62\n",
       "que               60\n",
       "https             58\n",
       "co                58\n",
       "t                 58\n",
       "a                 57\n",
       "não               52\n",
       "é                 38\n",
       "um                36\n",
       "eu                34\n",
       "com               33\n",
       "da                33\n",
       "do                31\n",
       "se                30\n",
       "gente             29\n",
       "rt                28\n",
       "tem               28\n",
       "pra               26\n",
       "meu               26\n",
       "em                25\n",
       "no                25\n",
       "na                24\n",
       "você              24\n",
       "cartão            24\n",
       "conta             22\n",
       "uma               22\n",
       "só                22\n",
       "                ... \n",
       "mozão              1\n",
       "aumentou           1\n",
       "garantido          1\n",
       "virtual”           1\n",
       "msm                1\n",
       "xaf1um2cqj         1\n",
       "p94dsdayhw         1\n",
       "sistema            1\n",
       "lotéricas          1\n",
       "faça               1\n",
       "eoleite            1\n",
       "✌🏽                 1\n",
       "bora               1\n",
       "conseguindo        1\n",
       "vejo               1\n",
       "bebada             1\n",
       "piscina            1\n",
       "gyroq3y6is         1\n",
       "esquecer           1\n",
       "kinnybouvier_      1\n",
       "rindo              1\n",
       "uhul               1\n",
       "e7oybscozu         1\n",
       "mlk                1\n",
       "vagas              1\n",
       "receber            1\n",
       "outra              1\n",
       "#nubank            1\n",
       "alguma             1\n",
       "fg9sugv9mc         1\n",
       "Name: 0, Length: 1114, dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Frequência dos Irrelevantes\n",
    "lista_nubank_irrelev = pd.DataFrame(pega_text(nubank_irrelev))\n",
    "lista_nubank_irrelev[0].value_counts()\n",
    "lista_nubank_irrelev[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequência Relativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nubank           0.056092\n",
       "o                0.026667\n",
       "de               0.024828\n",
       "e                0.023908\n",
       "eu               0.021609\n",
       "que              0.020690\n",
       "a                0.016092\n",
       "meu              0.015632\n",
       "me               0.013333\n",
       "co               0.012874\n",
       "https            0.012874\n",
       "t                0.012874\n",
       "um               0.012414\n",
       "não              0.011954\n",
       "é                0.011494\n",
       "cartão           0.010575\n",
       "do               0.010575\n",
       "no               0.009195\n",
       "uma              0.007356\n",
       "q                0.006897\n",
       "pra              0.006897\n",
       "na               0.006897\n",
       "com              0.006437\n",
       "to               0.006437\n",
       "só               0.005977\n",
       "limite           0.005517\n",
       "mais             0.005517\n",
       "nunca            0.005057\n",
       "tem              0.005057\n",
       "da               0.005057\n",
       "                   ...   \n",
       "deveria          0.000460\n",
       "pariu            0.000460\n",
       "cfo              0.000460\n",
       "valeriaales      0.000460\n",
       "melhores         0.000460\n",
       "eternidade       0.000460\n",
       "piso             0.000460\n",
       "moço             0.000460\n",
       "coisas           0.000460\n",
       "surpreenderam    0.000460\n",
       "392              0.000460\n",
       "desisto          0.000460\n",
       "seria            0.000460\n",
       "aguardando       0.000460\n",
       "500              0.000460\n",
       "blindadah        0.000460\n",
       "sites            0.000460\n",
       "ganhei           0.000460\n",
       "wan2gatnav       0.000460\n",
       "período          0.000460\n",
       "marialmeida93    0.000460\n",
       "gj2uj2obpj       0.000460\n",
       "indevidas        0.000460\n",
       "milhões          0.000460\n",
       "yasuqh           0.000460\n",
       "perder           0.000460\n",
       "momento          0.000460\n",
       "#nubank          0.000460\n",
       "vos              0.000460\n",
       "maioridade       0.000460\n",
       "Name: 0, Length: 833, dtype: float64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_nubank_relev[0].value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Irrelevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nubank           0.045441\n",
       "o                0.020950\n",
       "de               0.019770\n",
       "e                0.018294\n",
       "que              0.017704\n",
       "https            0.017114\n",
       "co               0.017114\n",
       "t                0.017114\n",
       "a                0.016819\n",
       "não              0.015344\n",
       "é                0.011213\n",
       "um               0.010623\n",
       "eu               0.010032\n",
       "com              0.009737\n",
       "da               0.009737\n",
       "do               0.009147\n",
       "se               0.008852\n",
       "gente            0.008557\n",
       "rt               0.008262\n",
       "tem              0.008262\n",
       "pra              0.007672\n",
       "meu              0.007672\n",
       "em               0.007377\n",
       "no               0.007377\n",
       "na               0.007082\n",
       "você             0.007082\n",
       "cartão           0.007082\n",
       "conta            0.006492\n",
       "uma              0.006492\n",
       "só               0.006492\n",
       "                   ...   \n",
       "mozão            0.000295\n",
       "aumentou         0.000295\n",
       "garantido        0.000295\n",
       "virtual”         0.000295\n",
       "msm              0.000295\n",
       "xaf1um2cqj       0.000295\n",
       "p94dsdayhw       0.000295\n",
       "sistema          0.000295\n",
       "lotéricas        0.000295\n",
       "faça             0.000295\n",
       "eoleite          0.000295\n",
       "✌🏽               0.000295\n",
       "bora             0.000295\n",
       "conseguindo      0.000295\n",
       "vejo             0.000295\n",
       "bebada           0.000295\n",
       "piscina          0.000295\n",
       "gyroq3y6is       0.000295\n",
       "esquecer         0.000295\n",
       "kinnybouvier_    0.000295\n",
       "rindo            0.000295\n",
       "uhul             0.000295\n",
       "e7oybscozu       0.000295\n",
       "mlk              0.000295\n",
       "vagas            0.000295\n",
       "receber          0.000295\n",
       "outra            0.000295\n",
       "#nubank          0.000295\n",
       "alguma           0.000295\n",
       "fg9sugv9mc       0.000295\n",
       "Name: 0, Length: 1114, dtype: float64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_nubank_irrelev[0].value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, estamos ensinando nosso treinador a identificar as probabilidades, para posteriormente fazer a identificação e a leitura. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Fazendo dicionários, para serem utilizados com objetivos na função'''\n",
    "\n",
    "linhas_mens = mensagens.Treinamento.apply(cleanup)[0]\n",
    "\n",
    "# Dicionário que guarda, dos relevantes, as palavras e quantas vezes apareceu\n",
    "lista_counts_relevante = (lista_nubank_relev[0].value_counts()).to_dict()\n",
    "\n",
    "# Dicionário que guarda a quantidade de relevantes e irrelevantes\n",
    "dicionario_counts_relevancia = (mensagens.Relevância.value_counts()).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-94.61\n"
     ]
    }
   ],
   "source": [
    "# Função que calcula as probabilidade de ser relevante\n",
    "def probabilidade_do_naive(lista_counts_relevante, dicionario_counts_relevancia, total, linhas_mens, lista_nubank_relev):\n",
    "    verossimilhança = 1\n",
    "    for word in linhas_mens:\n",
    "        for key, values in lista_counts_relevante.items():\n",
    "            if key == word:\n",
    "                verossimilhança *= (values+1)/(len(lista_nubank_relev)+len(linhas_mens))\n",
    "    \n",
    "    for rel, v in dicionario_counts_relevancia.items():\n",
    "        if rel == \"Relevante\":\n",
    "            total_rel = v\n",
    "    priori = total_rel/total\n",
    "    \n",
    "    return (('{0:.2f}').format(math.log10(verossimilhança * priori)))\n",
    "\n",
    "print(probabilidade_do_naive(lista_counts_relevante, dicionario_counts_relevancia, total, linhas_mens, lista_nubank_relev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-94.61',\n",
       " '-53.49',\n",
       " '-11.68',\n",
       " '-15.12',\n",
       " '-15.80',\n",
       " '-38.27',\n",
       " '-18.61',\n",
       " '-46.45',\n",
       " '-22.97',\n",
       " '-38.04',\n",
       " '-16.53',\n",
       " '-23.09',\n",
       " '-49.49',\n",
       " '-36.68',\n",
       " '-58.67',\n",
       " '-25.11',\n",
       " '-17.16',\n",
       " '-45.70',\n",
       " '-15.93',\n",
       " '-62.63',\n",
       " '-38.78',\n",
       " '-18.45',\n",
       " '-65.70',\n",
       " '-59.38',\n",
       " '-25.30',\n",
       " '-114.36',\n",
       " '-44.16',\n",
       " '-17.44',\n",
       " '-31.07',\n",
       " '-9.52',\n",
       " '-72.67',\n",
       " '-69.88',\n",
       " '-18.44',\n",
       " '-48.00',\n",
       " '-87.51',\n",
       " '-5.95',\n",
       " '-22.36',\n",
       " '-33.87',\n",
       " '-43.83',\n",
       " '-27.18',\n",
       " '-42.00',\n",
       " '-25.25',\n",
       " '-21.77',\n",
       " '-14.23',\n",
       " '-13.21',\n",
       " '-71.81',\n",
       " '-26.51',\n",
       " '-24.71',\n",
       " '-43.45',\n",
       " '-14.01',\n",
       " '-17.75',\n",
       " '-13.90',\n",
       " '-20.44',\n",
       " '-21.03',\n",
       " '-14.98',\n",
       " '-18.41',\n",
       " '-52.00',\n",
       " '-40.51',\n",
       " '-52.59',\n",
       " '-77.81',\n",
       " '-91.71',\n",
       " '-33.68',\n",
       " '-16.24',\n",
       " '-36.92',\n",
       " '-24.38',\n",
       " '-27.66',\n",
       " '-34.76',\n",
       " '-37.50',\n",
       " '-38.78',\n",
       " '-55.44',\n",
       " '-1.66',\n",
       " '-20.56',\n",
       " '-42.84',\n",
       " '-1.66',\n",
       " '-27.87',\n",
       " '-22.04',\n",
       " '-3.85',\n",
       " '-63.79',\n",
       " '-40.09',\n",
       " '-13.65',\n",
       " '-20.23',\n",
       " '-17.12',\n",
       " '-10.49',\n",
       " '-124.87',\n",
       " '-17.97',\n",
       " '-14.15',\n",
       " '-19.16',\n",
       " '-46.28',\n",
       " '-38.78',\n",
       " '-34.81',\n",
       " '-11.99',\n",
       " '-73.41',\n",
       " '-17.64',\n",
       " '-28.73',\n",
       " '-28.32',\n",
       " '-64.75',\n",
       " '-52.09',\n",
       " '-37.93',\n",
       " '-39.35',\n",
       " '-23.65',\n",
       " '-51.35',\n",
       " '-74.27',\n",
       " '-30.33',\n",
       " '-38.78',\n",
       " '-49.91',\n",
       " '-29.16',\n",
       " '-10.99',\n",
       " '-24.96',\n",
       " '-23.43',\n",
       " '-127.15',\n",
       " '-34.13',\n",
       " '-64.00',\n",
       " '-29.71',\n",
       " '-39.29',\n",
       " '-21.74',\n",
       " '-10.95',\n",
       " '-21.75',\n",
       " '-27.14',\n",
       " '-22.86',\n",
       " '-12.59',\n",
       " '-26.37',\n",
       " '-31.71',\n",
       " '-36.62',\n",
       " '-59.61',\n",
       " '-19.62',\n",
       " '-21.00',\n",
       " '-31.29',\n",
       " '-36.32',\n",
       " '-76.10',\n",
       " '-17.00',\n",
       " '-22.64',\n",
       " '-3.55',\n",
       " '-30.83',\n",
       " '-9.30',\n",
       " '-23.35',\n",
       " '-11.06',\n",
       " '-4.00',\n",
       " '-10.49',\n",
       " '-47.33',\n",
       " '-15.64',\n",
       " '-41.73',\n",
       " '-3.45',\n",
       " '-78.14',\n",
       " '-21.39',\n",
       " '-4.30',\n",
       " '-16.33',\n",
       " '-20.28',\n",
       " '-29.45',\n",
       " '-41.00',\n",
       " '-73.64',\n",
       " '-36.47',\n",
       " '-16.24',\n",
       " '-29.33',\n",
       " '-14.95',\n",
       " '-26.41',\n",
       " '-33.17',\n",
       " '-54.07',\n",
       " '-9.63',\n",
       " '-82.98',\n",
       " '-14.75',\n",
       " '-57.05',\n",
       " '-100.63',\n",
       " '-43.75',\n",
       " '-32.73',\n",
       " '-44.49',\n",
       " '-8.50',\n",
       " '-36.53',\n",
       " '-23.64',\n",
       " '-77.98',\n",
       " '-47.68',\n",
       " '-27.32',\n",
       " '-56.52',\n",
       " '-20.12',\n",
       " '-26.50',\n",
       " '-36.65',\n",
       " '-10.17',\n",
       " '-78.93',\n",
       " '-16.19',\n",
       " '-44.52',\n",
       " '-11.92',\n",
       " '-38.78',\n",
       " '-21.83',\n",
       " '-27.52',\n",
       " '-90.84',\n",
       " '-14.96',\n",
       " '-23.76',\n",
       " '-12.36',\n",
       " '-23.17',\n",
       " '-13.93',\n",
       " '-67.33',\n",
       " '-24.83',\n",
       " '-13.53',\n",
       " '-51.42',\n",
       " '-67.56',\n",
       " '-39.28',\n",
       " '-123.57',\n",
       " '-78.41',\n",
       " '-10.76',\n",
       " '-44.37',\n",
       " '-32.72',\n",
       " '-29.20',\n",
       " '-35.26',\n",
       " '-4.70',\n",
       " '-36.05',\n",
       " '-32.41',\n",
       " '-22.75',\n",
       " '-20.35',\n",
       " '-29.30',\n",
       " '-53.89',\n",
       " '-41.69',\n",
       " '-8.91',\n",
       " '-30.52',\n",
       " '-40.43',\n",
       " '-33.01',\n",
       " '-8.35',\n",
       " '-7.26',\n",
       " '-11.29',\n",
       " '-8.17',\n",
       " '-16.53',\n",
       " '-39.73',\n",
       " '-16.04',\n",
       " '-26.72',\n",
       " '-57.71',\n",
       " '-6.27',\n",
       " '-65.43',\n",
       " '-38.78',\n",
       " '-15.54',\n",
       " '-47.90',\n",
       " '-39.48',\n",
       " '-16.13',\n",
       " '-25.40',\n",
       " '-18.74',\n",
       " '-14.79',\n",
       " '-48.70',\n",
       " '-32.98',\n",
       " '-21.82',\n",
       " '-33.05',\n",
       " '-12.02',\n",
       " '-8.13',\n",
       " '-44.28',\n",
       " '-13.83',\n",
       " '-29.06',\n",
       " '-38.78',\n",
       " '-17.37',\n",
       " '-31.43',\n",
       " '-19.60',\n",
       " '-46.94',\n",
       " '-21.42',\n",
       " '-134.79',\n",
       " '-7.52',\n",
       " '-14.41',\n",
       " '-7.34',\n",
       " '-59.55',\n",
       " '-11.36',\n",
       " '-10.89',\n",
       " '-24.67',\n",
       " '-9.45',\n",
       " '-25.50',\n",
       " '-26.53',\n",
       " '-33.02',\n",
       " '-50.02',\n",
       " '-12.61',\n",
       " '-13.09',\n",
       " '-4.30',\n",
       " '-36.00',\n",
       " '-96.20',\n",
       " '-20.30',\n",
       " '-23.82',\n",
       " '-13.06',\n",
       " '-31.61',\n",
       " '-19.26',\n",
       " '-13.27',\n",
       " '-26.21',\n",
       " '-17.91',\n",
       " '-53.95',\n",
       " '-32.19',\n",
       " '-49.05',\n",
       " '-28.11',\n",
       " '-5.71',\n",
       " '-17.34',\n",
       " '-88.10',\n",
       " '-47.17',\n",
       " '-14.95',\n",
       " '-121.26',\n",
       " '-49.91',\n",
       " '-79.64',\n",
       " '-11.01',\n",
       " '-24.37',\n",
       " '-38.78',\n",
       " '-90.80',\n",
       " '-57.41',\n",
       " '-38.78',\n",
       " '-70.26',\n",
       " '-25.07',\n",
       " '-38.78',\n",
       " '-44.10',\n",
       " '-90.75',\n",
       " '-19.74',\n",
       " '-25.67',\n",
       " '-18.04']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_relevante = [0]*300\n",
    "\n",
    "i = 0\n",
    "for h in probs_relevante:\n",
    "    linhas_mens = mensagens.Treinamento.apply(cleanup)[i]\n",
    "    probs_relevante[i] = probabilidade_do_naive(lista_counts_relevante, dicionario_counts_relevancia, total, linhas_mens, lista_nubank_relev)\n",
    "    i += 1\n",
    "probs_relevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Irrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionário que guarda, dos irrelevantes, as palavras e quantas vezes apareceu\n",
    "lista_counts_irrelevante = (lista_nubank_irrelev[0].value_counts()).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que calcula as probabilidade de ser irrelevante\n",
    "def probabilidade_do_naive_irr(lista_counts_irrelevante, dicionario_counts_relevancia, total, linhas_mens, lista_nubank_irrelev):\n",
    "    verossimilhança = 1\n",
    "    # Identificando a quantidade e calculando a probabilidade de cada palavra do tweet\n",
    "    for word in linhas_mens:\n",
    "        for key, values in lista_counts_irrelevante.items():\n",
    "            if key == word:\n",
    "                verossimilhança *= (values+1) / (len(lista_nubank_irrelev)+len(linhas_mens))\n",
    "    \n",
    "    # Pegando a probabilidade e dividindo pelo total, usando Naive Bayes\n",
    "    for rel, v in dicionario_counts_relevancia.items():\n",
    "        if rel == \"Irrelevante\":\n",
    "            total_rel = v\n",
    "    priori = total_rel/total\n",
    "    \n",
    "    return (('{0:.2f}').format(math.log10(verossimilhança * priori)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_irrelevante = [0]*300\n",
    "\n",
    "i = 0\n",
    "for h in probs_irrelevante:\n",
    "    linhas_mens = mensagens.Treinamento.apply(cleanup)[i]\n",
    "    probs_irrelevante[i] = probabilidade_do_naive_irr(lista_counts_irrelevante, dicionario_counts_relevancia, total, linhas_mens, lista_nubank_irrelev)\n",
    "    i += 1\n",
    "#probs_irrelevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste = pd.ExcelFile(\"Nubank.xlsx\")\n",
    "df_teste1 = pd.read_excel(df_teste, 'Teste')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criando os argumentos que entraram na função criada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Número de tweets relevantes e irrelevantes e seu total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A quantidade de cada cada um é: \n",
      "\n",
      " Irrelevante    121\n",
      "Relevante       79\n",
      "Name: Relevância, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Irrelevante': 121, 'Relevante': 79}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_teste1.Relevância = mensagens.Relevância.astype('category')\n",
    "df_teste1.Relevância.cat.categories = ('Irrelevante', 'Relevante')\n",
    "\n",
    "relevante_teste = df_teste1[df_teste1.Relevância==\"Relevante\"]\n",
    "irrelevante_teste = df_teste1[df_teste1.Relevância==\"Irrelevante\"]\n",
    "\n",
    "total_teste = len(relevante_teste) + len(irrelevante_teste)\n",
    "\n",
    "print(\"A quantidade de cada cada um é: \\n\\n\", df_teste1.Relevância.value_counts())\n",
    "dicionario_counts_relevância1 = (df_teste1.Relevância.value_counts()).to_dict()\n",
    "dicionario_counts_relevância1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequência absoluta das palavras nos tweets relevantes e transformando em dicionário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando a função apply para fazer a limpeza nas mensagens\n",
    "df_teste2_rel = relevante_teste.Teste.apply(cleanup)\n",
    "df_teste2_rel = pd.DataFrame(pega_text(df_teste2_rel))\n",
    "\n",
    "dict_teste_counts_rel = (df_teste2_rel[0].value_counts()).to_dict()\n",
    "total_teste_rel = df_teste2_rel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Irrelevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequência absoluta das palavras nos tweets irrelevantes e tranformando em dicionário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste2_irrel = pd.DataFrame(pega_text(irrelevante_teste.Teste.apply(cleanup)))\n",
    "dict_teste_counts_irrel = (df_teste2_irrel[0].value_counts()).to_dict()\n",
    "total_teste_irrel = df_teste2_irrel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "linhas_mens_teste = df_teste1.Teste.apply(cleanup)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-9.76\n"
     ]
    }
   ],
   "source": [
    "print(probabilidade_do_naive_irr(dict_teste_counts_rel, dicionario_counts_relevância1, total, linhas_mens_teste, total_teste_rel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_relevante2 = [0]*200\n",
    "\n",
    "i = 0\n",
    "for elemento in probs_relevante2:\n",
    "    linhas_mens_teste = df_teste1.Teste.apply(cleanup)[i]\n",
    "    probs_relevante2[i] = probabilidade_do_naive(dict_teste_counts_rel, dicionario_counts_relevância1, total_teste, linhas_mens_teste, df_teste2_rel)\n",
    "    i += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Irrelevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_irrelevante2 = [0]*200\n",
    "\n",
    "i = 0\n",
    "for elemento in probs_irrelevante2:\n",
    "    linhas_mens_teste = df_teste1.Teste.apply(cleanup)[i]\n",
    "    probs_irrelevante2[i] = probabilidade_do_naive_irr(dict_teste_counts_irrel, dicionario_counts_relevância1, total_teste, linhas_mens_teste, df_teste2_irrel)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparation(relevante, irrelevante):\n",
    "    i = 0 \n",
    "    result = []\n",
    "    for e in relevante:\n",
    "        if relevante[i] > irrelevante[i]:\n",
    "            result.append(\"Relevante\")\n",
    "        elif relevante[i] < irrelevante[i]:\n",
    "            result.append(\"Irrelevante\")\n",
    "        # É muito improvável que ocorra. Porém, se ocorrer, consideramos que é irrelevante\n",
    "        else:\n",
    "            result.append(0)\n",
    "        i += 1    \n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado_das_relevancias = comparation(probs_relevante2, probs_irrelevante2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: 160, False: 40\n"
     ]
    }
   ],
   "source": [
    "serie = []\n",
    "for linha in df_teste1.Relevância:\n",
    "    serie.append(linha)\n",
    "\n",
    "def comparação_com_classificados(relevancias_comparativas, classificados):\n",
    "    i = 0 \n",
    "    true = 0\n",
    "    false = 0\n",
    "    comparação_final = []\n",
    "    for e in classificados:\n",
    "        if relevancias_comparativas[i] == classificados[i]:\n",
    "            comparação_final.append(True)\n",
    "            true += 1\n",
    "        else:\n",
    "            comparação_final.append(False)\n",
    "            false += 1\n",
    "        i+=1\n",
    "            \n",
    "    print(f'True: {true}, False: {false}')    \n",
    "    \n",
    "    return comparação_final\n",
    "\n",
    "result = comparação_com_classificados(resultado_das_relevancias, serie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verdadeiros positivos: 32.0%\n",
      "Falsos positivos: 12.5%\n",
      "Verdadeiros negativos: 48.0%\n",
      "Falsos negativos: 7.5%\n"
     ]
    }
   ],
   "source": [
    "serie\n",
    "resultado_das_relevancias\n",
    "\n",
    "def porcentagem(serie, resultado_das_relevancias):\n",
    "    i = 0\n",
    "    soma = 0\n",
    "    ver_pos = 0\n",
    "    fal_pos = 0\n",
    "    ver_neg = 0\n",
    "    fal_neg = 0\n",
    "    \n",
    "    for elemento in serie:\n",
    "        if serie[i] == \"Relevante\" and resultado_das_relevancias[i]== \"Relevante\":\n",
    "            ver_pos += 1\n",
    "        elif serie[i] == \"Irrelevante\" and resultado_das_relevancias[i]== \"Irrelevante\":\n",
    "            ver_neg += 1\n",
    "        elif serie[i] == \"Relevante\" and resultado_das_relevancias[i]== \"Irrelevante\":\n",
    "            fal_neg += 1\n",
    "        elif serie[i] == \"Irrelevante\" and resultado_das_relevancias[i]== \"Relevante\":\n",
    "            fal_pos += 1\n",
    "        soma += 1\n",
    "        i += 1\n",
    "            \n",
    "    return ver_pos/soma, ver_neg/soma, fal_pos/soma, fal_neg/soma\n",
    "\n",
    "lista_porcentagem = porcentagem(serie, resultado_das_relevancias)\n",
    "list_porc = []\n",
    "i = 0\n",
    "for e in lista_porcentagem:\n",
    "    e *= 100\n",
    "    list_porc.append(e)\n",
    "    i += 1\n",
    "    \n",
    "    \n",
    "print(f'Verdadeiros positivos: {list_porc[0]}%')\n",
    "print(f'Falsos positivos: {list_porc[2]}%')\n",
    "print(f'Verdadeiros negativos: {list_porc[1]}%')\n",
    "print(f'Falsos negativos: {list_porc[3]}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
