{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nome**: Jonas da Silva Lopes\n",
    "\n",
    "**Nome**: William Silva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Classificador autom√°tico de sentimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install tweepy\n",
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import emoji\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "import re \n",
    "import functools\n",
    "import operator\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticando no  Twitter\n",
    "\n",
    "* Conta: ***@William48253649***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Identificador da conta no twitter: @William48253649\n",
    "\n",
    "#leitura do arquivo no formato JSON\n",
    "with open('auth.pass') as fp:    \n",
    "    data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca\n",
    "auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolha de um produto e coleta das mensagens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Produto escolhido\n",
    "produto = 'Nubank'\n",
    "\n",
    "#Quantidade m√≠nima de mensagens capturadas\n",
    "n = 500\n",
    "#Quantidade m√≠nima de mensagens para a base de treinamento\n",
    "t = 300\n",
    "\n",
    "#Filtro de l√≠ngua\n",
    "lang = 'pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capturando os dados do twitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Cria um objeto para a captura\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#Inicia a captura\n",
    "i = 1\n",
    "msgs = []\n",
    "for msg in tweepy.Cursor(api.search, q=produto, lang=lang, tweet_mode=\"extended\").items():    \n",
    "    msgs.append(msg.full_text.lower()) #Lower para deixar tudo min√∫sculo e facilitar a compara√ß√£o\n",
    "    i += 1\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "#Embaralhando as mensagens para reduzir um poss√≠vel vi√©s\n",
    "shuffle(msgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando os dados em uma planilha Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Verifica se o arquivo n√£o existe para n√£o substituir um conjunto pronto\n",
    "if not os.path.isfile('./{0}.xlsx'.format(produto)):\n",
    "    \n",
    "    #Abre o arquivo para escrita\n",
    "    writer = pd.ExcelWriter('{0}.xlsx'.format(produto))\n",
    "\n",
    "    #divide o conjunto de mensagens em duas planilhas\n",
    "    dft = pd.DataFrame({'Treinamento' : pd.Series(msgs[:t])}).set()\n",
    "    dft.to_excel(excel_writer = writer, sheet_name = 'Treinamento', index = False)\n",
    "\n",
    "    dfc = pd.DataFrame({'Teste' : pd.Series(msgs[t:])}).set()\n",
    "    dfc.to_excel(excel_writer = writer, sheet_name = 'Teste', index = False)\n",
    "\n",
    "    #fecha o arquivo\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Classificando as mensagens na coragem\n",
    "\n",
    "Ap√≥s realizar a classifica√ß√£o manual das mensagens, como irrelevante (0) ou relevante (1), partimos para  a mudan√ßa desses valores para algo mais palp√°vel para a an√°lise. Com isso, fazemos a altera√ß√£o que pode ser vista abaixo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas, para realizar isso, primeiro foi necess√°rio determinar crit√©rios para a classifica√ß√£o:\n",
    "\n",
    "- Mencionar o produto;\n",
    "- A men√ß√£o ao produto deve ser acompanhada de uma opini√£o;\n",
    "- A opini√£o pode ser demonstrada na forma de indaga√ß√µes, reclama√ß√µes, pode envolver sarcasmo, elogios e sugest√µes sobre servi√ßos;\n",
    "- A opini√£o afirmada deve ser clara;\n",
    "- Emoctions tamb√©m representam opini√µes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A quantidade de cada cada um √©: \n",
      "\n",
      " Irrelevante    184\n",
      "Relevante      116\n",
      "Name: Relev√¢ncia, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "mensagens = pd.read_excel(\"Nubank.xlsx\")\n",
    "mensagens.Relev√¢ncia = mensagens.Relev√¢ncia.astype('category')\n",
    "mensagens.Relev√¢ncia.cat.categories = ('Irrelevante', 'Relevante')\n",
    "\n",
    "print(\"A quantidade de cada cada um √©: \\n\\n\", mensagens.Relev√¢ncia.value_counts())\n",
    "\n",
    "relevante = mensagens[mensagens.Relev√¢ncia==\"Relevante\"]\n",
    "irrelevante = mensagens[mensagens.Relev√¢ncia==\"Irrelevante\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A probabilidade de ser relevante √© 38.666666666666664 %\n",
      "A probabilidade de ser irrelevante √© 61.33333333333333 %\n"
     ]
    }
   ],
   "source": [
    "'''A Partir dos dados obtidos, nota-se que:\n",
    "        p(relevante) = 116/300\n",
    "        p(irrelevante) = 184/300\n",
    "'''\n",
    "p_relev = 116/300*100\n",
    "print(\"A probabilidade de ser relevante √©\", p_relev, \"%\")\n",
    "\n",
    "p_irrelev = 184/300*100\n",
    "print(\"A probabilidade de ser irrelevante √©\", p_irrelev, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      rindo mas preocupada pois cada dia parece que ...\n",
       "6          eu amo o nubank mesmo https://t.co/rrpb89yes9\n",
       "7      meu pai pediu um cart√£o novo pra mim pra pegar...\n",
       "8          quem inventou o nubank nem √© gente, √© um anjo\n",
       "11     @castrocastrado @nubank se quiser eu te indico...\n",
       "12     @1masterball @haunted_electra me assusta muito...\n",
       "13     preju√≠zo nubank: banco tem 12 milh√µes de clien...\n",
       "15     @marialmeida93 @thaioliv_ @nubank menina que t...\n",
       "19     @nubank @itoncrf_ e assim mesmo n me aprovaram...\n",
       "21          depois de anos tentando,fui aceita no nubank\n",
       "22     rt @afropreticinha: aff coma assim o cart√£o da...\n",
       "25     fiquei assustada quando vi que minha fatura do...\n",
       "26     nubank nunca me liberou cr√©dito, agr q libera....\n",
       "27               meu nubank chegouüòç vos declaro fal√™ncia\n",
       "28     @lucasafoliveira @nubank ele trava assim e n√£o...\n",
       "31     s√©rio, se eu perder minha bolsa por conta do n...\n",
       "32        eu toda com meu nubank https://t.co/4av08gusbn\n",
       "33     querido @nubank, a gente queria tanto testar e...\n",
       "34     eu amo o @nubank de verdade, de cora√ß√£o, mas n...\n",
       "36     esperando o @nubank lan√ßar seu plano de previd...\n",
       "42     felizmente a nubank me aceitou esse momento √© ...\n",
       "44                         feliz q a nubank me aceitouuu\n",
       "45     maior defeito da nubank √© a facilidade p clona...\n",
       "46     eu n√£o tenho cart√£o nubank, mas eu amo essa ca...\n",
       "48     o @nubank n√£o libera a op√ß√£o de credito pro me...\n",
       "56     @robzgf quer mimo maior que um cart√£o livre de...\n",
       "57     @nubank @awarenesswoman @mabzinhaa a√≠ nubankin...\n",
       "59     eu: nossa vou ser mais reservada sabe n vou fa...\n",
       "60     estou muito orgulhoso da equipe de vendas. mes...\n",
       "63     eu ia ficar um nojo se o nubank autorizasse pa...\n",
       "                             ...                        \n",
       "231      @maluulana @nubank e eu ainda na eterna espera.\n",
       "233    pq q eu fui a √∫nica pessoa do mundo q n√£o ganh...\n",
       "234    @pianoetlux bah nem, nubank me odeia, eles me ...\n",
       "236    a central de atendimento da nubank √© me trata ...\n",
       "239    eu t√¥ assi\\npena que j√° vai tudo s√≥ hoje \\nnub...\n",
       "241    @1masterball eu tinha medo de fazer um nubank,...\n",
       "244    nubank ta cheio desses problema ai, tenho √© me...\n",
       "247    @valeriaales @nandoida @helogb__ @nubank @nuba...\n",
       "248    gente, j√° imaginou q louco se d√° um problema c...\n",
       "250                  estou ansiosa pro meu nubank chegar\n",
       "252    seria tao lindo se a @nubank deixasse eu fazer...\n",
       "254                           meu cart√£o nubank chegou ü§ó\n",
       "255    @dgianygarcia deus que me livre, esse nubank q...\n",
       "259    @nubank ai voc√™s s√£o queridos demais ‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è ob...\n",
       "260    isso tem acontecido demais com o nubank, pelo ...\n",
       "261                           @nubank conte cmg pra tudo\n",
       "264    euzinha. inclusive, @nubank aumenta meu limite...\n",
       "265    bixo o atendimento do @nubank √© sensacional, c...\n",
       "268                         nubank √© o melhor banco, pqp\n",
       "274    next e nubank duas bombas, essas porras n√£o li...\n",
       "279    @lanaalmeidaofc @nubank nunca decepciona, o me...\n",
       "280    @__chicao__ @nubank o meu a \"sorte\" √© que foi ...\n",
       "283    eu perguntei de um amigo se ele queria que eu ...\n",
       "287    n√£o aguento mais o @nubank  me lembrando de pa...\n",
       "289    aconteceu o mesmo comigo, compraram enxoval de...\n",
       "290    @nubank corre aqui por favor, to perdida. o ch...\n",
       "292    @__chicao__ @gtcarvalh0 @nubank passei por iss...\n",
       "296    to desde o dia 1¬∫ tentando pagar a porra da mi...\n",
       "298    @nubank @yasuqh kakakakakakkak pqp eu quero se...\n",
       "299    @1masterball @renatojg nossa! clonaram um nuba...\n",
       "Name: Treinamento, Length: 116, dtype: object"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Fun√ß√£o que troca pontua√ß√£o por espa√ßo '''\n",
    "def cleanup(text):\n",
    "    punctuation = '[!\\-.:?;/,|@\"\\'()]'\n",
    "    pattern = re.compile(punctuation)\n",
    "    # Abaixo, determina que se troca por espa√ßo\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    \n",
    "    emoji_dividir = emoji.get_emoji_regexp().split(text_subbed)\n",
    "    espaco_dividir = [substr.split() for substr in emoji_dividir]\n",
    "    split = functools.reduce(operator.concat, espaco_dividir)\n",
    "    \n",
    "    return split\n",
    "\n",
    "# Usando a fun√ß√£o apply para fazer a limpeza nas mensagens\n",
    "nubank_relev = relevante.Treinamento.apply(cleanup)\n",
    "nubank_irrelev = irrelevante.Treinamento.apply(cleanup)\n",
    "\n",
    "# Pegando as palavras da lista de Relevantes para contar\n",
    "def pega_text(texto):\n",
    "    # Pega as palavras para colocar numa lista\n",
    "    lista = []\n",
    "    i = 0\n",
    "    for linha in texto:\n",
    "        if len(linha) > 1:\n",
    "            while i < len(linha):\n",
    "                lista.append(linha[i])\n",
    "                i += 1  \n",
    "            i = 0\n",
    "        elif len(linha) != 1 and (len(linha)-1) != 1:\n",
    "            a = texto\n",
    "            return a \n",
    "    return lista\n",
    "\n",
    "relevante.Treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequ√™ncia Absoluta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nubank            122\n",
       "o                  58\n",
       "de                 54\n",
       "e                  52\n",
       "eu                 47\n",
       "que                45\n",
       "a                  35\n",
       "meu                34\n",
       "me                 29\n",
       "co                 28\n",
       "t                  28\n",
       "https              28\n",
       "um                 27\n",
       "n√£o                26\n",
       "√©                  25\n",
       "do                 23\n",
       "cart√£o             23\n",
       "no                 20\n",
       "uma                16\n",
       "pra                15\n",
       "na                 15\n",
       "q                  15\n",
       "to                 14\n",
       "com                14\n",
       "s√≥                 13\n",
       "mais               12\n",
       "limite             12\n",
       "tem                11\n",
       "da                 11\n",
       "nunca              11\n",
       "                 ... \n",
       "robertoper3ir4      1\n",
       "for√ßas              1\n",
       "anoja               1\n",
       "paci√™ncia           1\n",
       "outro               1\n",
       "enxoval             1\n",
       "pianoetlux          1\n",
       "quiser              1\n",
       "sempre              1\n",
       "6                   1\n",
       "tira                1\n",
       "üòé                   1\n",
       "vazou               1\n",
       "dado                1\n",
       "cfo                 1\n",
       "convenci            1\n",
       "representa          1\n",
       "fechar              1\n",
       "passo               1\n",
       "itoncrf_            1\n",
       "hauahuah            1\n",
       "estava              1\n",
       "vejo                1\n",
       "elabora√ß√£o          1\n",
       "blindadah           1\n",
       "carteiro            1\n",
       "in√≠cio              1\n",
       "valor               1\n",
       "livramento          1\n",
       "chat                1\n",
       "Name: 0, Length: 833, dtype: int64"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Frequ√™ncia dos Relevantes\n",
    "lista_nubank_relev = pd.DataFrame(pega_text(nubank_relev))\n",
    "lista_nubank_relev[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Irrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nubank             154\n",
       "o                   71\n",
       "de                  67\n",
       "e                   62\n",
       "que                 60\n",
       "co                  58\n",
       "https               58\n",
       "t                   58\n",
       "a                   57\n",
       "n√£o                 52\n",
       "√©                   38\n",
       "um                  36\n",
       "eu                  34\n",
       "com                 33\n",
       "da                  33\n",
       "do                  31\n",
       "se                  30\n",
       "gente               29\n",
       "tem                 28\n",
       "rt                  28\n",
       "meu                 26\n",
       "pra                 26\n",
       "em                  25\n",
       "no                  25\n",
       "cart√£o              24\n",
       "voc√™                24\n",
       "na                  24\n",
       "s√≥                  22\n",
       "uma                 22\n",
       "conta               22\n",
       "                  ... \n",
       "serve                1\n",
       "rolando              1\n",
       "interferir           1\n",
       "minhas               1\n",
       "zq6cca3lv1           1\n",
       "hahahaa              1\n",
       "castrocastrado       1\n",
       "consiga              1\n",
       "pagou                1\n",
       "fechar               1\n",
       "porra                1\n",
       "acesso               1\n",
       "barras               1\n",
       "pedroconradoma2      1\n",
       "itoncrf_             1\n",
       "alo                  1\n",
       "daqueles             1\n",
       "fechei               1\n",
       "palma‚Ä¶               1\n",
       "ajudai               1\n",
       "gaaay                1\n",
       "seguran√ßa            1\n",
       "codhab               1\n",
       "in√≠cio               1\n",
       "devia                1\n",
       "apostei              1\n",
       "spam                 1\n",
       "dessa                1\n",
       "dadarkp3             1\n",
       "xxnewbe              1\n",
       "Name: 0, Length: 1114, dtype: int64"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Frequ√™ncia dos Irrelevantes\n",
    "lista_nubank_irrelev = pd.DataFrame(pega_text(nubank_irrelev))\n",
    "lista_nubank_irrelev[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequ√™ncia Relativa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nubank            0.056092\n",
       "o                 0.026667\n",
       "de                0.024828\n",
       "e                 0.023908\n",
       "eu                0.021609\n",
       "que               0.020690\n",
       "a                 0.016092\n",
       "meu               0.015632\n",
       "me                0.013333\n",
       "co                0.012874\n",
       "t                 0.012874\n",
       "https             0.012874\n",
       "um                0.012414\n",
       "n√£o               0.011954\n",
       "√©                 0.011494\n",
       "do                0.010575\n",
       "cart√£o            0.010575\n",
       "no                0.009195\n",
       "uma               0.007356\n",
       "pra               0.006897\n",
       "na                0.006897\n",
       "q                 0.006897\n",
       "to                0.006437\n",
       "com               0.006437\n",
       "s√≥                0.005977\n",
       "mais              0.005517\n",
       "limite            0.005517\n",
       "tem               0.005057\n",
       "da                0.005057\n",
       "nunca             0.005057\n",
       "                    ...   \n",
       "robertoper3ir4    0.000460\n",
       "for√ßas            0.000460\n",
       "anoja             0.000460\n",
       "paci√™ncia         0.000460\n",
       "outro             0.000460\n",
       "enxoval           0.000460\n",
       "pianoetlux        0.000460\n",
       "quiser            0.000460\n",
       "sempre            0.000460\n",
       "6                 0.000460\n",
       "tira              0.000460\n",
       "üòé                 0.000460\n",
       "vazou             0.000460\n",
       "dado              0.000460\n",
       "cfo               0.000460\n",
       "convenci          0.000460\n",
       "representa        0.000460\n",
       "fechar            0.000460\n",
       "passo             0.000460\n",
       "itoncrf_          0.000460\n",
       "hauahuah          0.000460\n",
       "estava            0.000460\n",
       "vejo              0.000460\n",
       "elabora√ß√£o        0.000460\n",
       "blindadah         0.000460\n",
       "carteiro          0.000460\n",
       "in√≠cio            0.000460\n",
       "valor             0.000460\n",
       "livramento        0.000460\n",
       "chat              0.000460\n",
       "Name: 0, Length: 833, dtype: float64"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_nubank_relev[0].value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Irrelevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nubank             0.045441\n",
       "o                  0.020950\n",
       "de                 0.019770\n",
       "e                  0.018294\n",
       "que                0.017704\n",
       "co                 0.017114\n",
       "https              0.017114\n",
       "t                  0.017114\n",
       "a                  0.016819\n",
       "n√£o                0.015344\n",
       "√©                  0.011213\n",
       "um                 0.010623\n",
       "eu                 0.010032\n",
       "com                0.009737\n",
       "da                 0.009737\n",
       "do                 0.009147\n",
       "se                 0.008852\n",
       "gente              0.008557\n",
       "tem                0.008262\n",
       "rt                 0.008262\n",
       "meu                0.007672\n",
       "pra                0.007672\n",
       "em                 0.007377\n",
       "no                 0.007377\n",
       "cart√£o             0.007082\n",
       "voc√™               0.007082\n",
       "na                 0.007082\n",
       "s√≥                 0.006492\n",
       "uma                0.006492\n",
       "conta              0.006492\n",
       "                     ...   \n",
       "serve              0.000295\n",
       "rolando            0.000295\n",
       "interferir         0.000295\n",
       "minhas             0.000295\n",
       "zq6cca3lv1         0.000295\n",
       "hahahaa            0.000295\n",
       "castrocastrado     0.000295\n",
       "consiga            0.000295\n",
       "pagou              0.000295\n",
       "fechar             0.000295\n",
       "porra              0.000295\n",
       "acesso             0.000295\n",
       "barras             0.000295\n",
       "pedroconradoma2    0.000295\n",
       "itoncrf_           0.000295\n",
       "alo                0.000295\n",
       "daqueles           0.000295\n",
       "fechei             0.000295\n",
       "palma‚Ä¶             0.000295\n",
       "ajudai             0.000295\n",
       "gaaay              0.000295\n",
       "seguran√ßa          0.000295\n",
       "codhab             0.000295\n",
       "in√≠cio             0.000295\n",
       "devia              0.000295\n",
       "apostei            0.000295\n",
       "spam               0.000295\n",
       "dessa              0.000295\n",
       "dadarkp3           0.000295\n",
       "xxnewbe            0.000295\n",
       "Name: 0, Length: 1114, dtype: float64"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_nubank_irrelev[0].value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando o Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1masterball', 'renatojg', 'nossa', 'clonaram', 'um', 'nubank', 'üò±']\n"
     ]
    }
   ],
   "source": [
    "for linha in mensagens.Treinamento:\n",
    "    lista_linha = cleanup(linha)\n",
    "    '''chama a fun√ß√£o com o atributo a'''\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-326-dc7a86a38b65>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmensagens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTreinamento\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-321-ba5cdddd0146>\u001b[0m in \u001b[0;36mcleanup\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mpattern\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Abaixo, determina que se troca por espa√ßo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mtext_subbed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0memoji_dividir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0memoji\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_emoji_regexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext_subbed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36msub\u001b[1;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[1;32m--> 192\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "a = cleanup(mensagens.Treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que periodicamente realiza an√°lise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
